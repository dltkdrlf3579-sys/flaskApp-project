import os
import logging
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_file, session, redirect, url_for
from werkzeug.serving import run_simple
from werkzeug.utils import secure_filename
from config.menu import MENU_CONFIG
from database_config import db_config, partner_manager
import sqlite3
import math

def generate_manual_accident_number(cursor):
    """ìˆ˜ê¸°ì…ë ¥ ì‚¬ê³ ë²ˆí˜¸ ìë™ ìƒì„± (ACCYYMMDD00 í˜•ì‹)"""
    today = datetime.now()
    date_part = today.strftime('%y%m%d')  # 240822
    
    # ì˜¤ëŠ˜ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ë²ˆí˜¸ ì¡°íšŒ
    cursor.execute("""
        SELECT accident_number 
        FROM accidents_cache 
        WHERE accident_number LIKE ?
        ORDER BY accident_number DESC
        LIMIT 1
    """, (f'ACC{date_part}%',))
    
    last = cursor.fetchone()
    if last:
        # ACC24082203 â†’ 04
        seq = int(last[0][-2:]) + 1
    else:
        seq = 1
    
    return f'ACC{date_part}{seq:02d}'

app = Flask(__name__, static_folder='static')

# ë©”ë‰´ ì„¤ì •
menu = MENU_CONFIG

# ì„¤ì • íŒŒì¼ì—ì„œ í™˜ê²½ ì„¤ì • ë¡œë“œ
app.secret_key = db_config.config.get('DEFAULT', 'SECRET_KEY')
app.debug = db_config.config.getboolean('DEFAULT', 'DEBUG')

# Jinja2 í•„í„° ì¶”ê°€ (JSON íŒŒì‹±ìš©)
import json
def from_json_filter(value):
    try:
        return json.loads(value) if value else []
    except:
        return []
app.jinja_env.filters['from_json'] = from_json_filter

DB_PATH = db_config.local_db_path
PASSWORD = db_config.config.get('DEFAULT', 'EDIT_PASSWORD')
ADMIN_PASSWORD = db_config.config.get('DEFAULT', 'ADMIN_PASSWORD')
UPLOAD_FOLDER = db_config.config.get('DEFAULT', 'UPLOAD_FOLDER')

# ê´€ë¦¬ì ì¸ì¦ í•¨ìˆ˜
def require_admin_auth(f):
    """ê´€ë¦¬ì ì¸ì¦ì´ í•„ìš”í•œ í•¨ìˆ˜ì— ì‚¬ìš©í•˜ëŠ” decorator"""
    from functools import wraps
    
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # ì„¸ì…˜ì—ì„œ ê´€ë¦¬ì ì¸ì¦ í™•ì¸
        if session.get('admin_authenticated') != True:
            # ì¸ì¦ì´ ì•ˆëœ ê²½ìš° ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
            return render_template('admin-login.html', 
                                 redirect_url=request.url,
                                 menu=MENU_CONFIG)
        return f(*args, **kwargs)
    return decorated_function

# ë“œë¡­ë‹¤ìš´ ì½”ë“œ ë§¤í•‘
DROPDOWN_MAPPINGS = {
    'column3': {
        'COLUMN3_001': 'ì§„í–‰ì¤‘',
        'COLUMN3_002': 'ì™„ë£ŒëŒ€ê¸°',
        'COLUMN3_003': 'ë³´ë¥˜',
        'COLUMN3_004': 'ë³´ë¥˜3'
    }
}

def convert_dropdown_code(column_key, code):
    """ë“œë¡­ë‹¤ìš´ ì½”ë“œë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜"""
    if column_key in DROPDOWN_MAPPINGS:
        return DROPDOWN_MAPPINGS[column_key].get(code, code)
    return code

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, db_config.config.get('LOGGING', 'LOG_LEVEL')),
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(db_config.config.get('LOGGING', 'LOG_FILE')),
        logging.StreamHandler()
    ]
)

# Flask í…œí”Œë¦¿ ìë™ ë¦¬ë¡œë“œ ì„¤ì •
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0

# Jinja2 í…œí”Œë¦¿ ìºì‹œ ë¹„ìš°ê¸°
app.jinja_env.cache = {}

def init_db():
    """ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™” ë° ë°ì´í„° ë™ê¸°í™”"""
    # ë¡œì»¬ DB í…Œì´ë¸” ì´ˆê¸°í™” (partner_managerì—ì„œ ì²˜ë¦¬)
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # í˜ì´ì§€ í…Œì´ë¸”ë§Œ ì—¬ê¸°ì„œ ê´€ë¦¬
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS pages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            url TEXT UNIQUE,
            title TEXT,
            content TEXT
        )
    ''')
    
    # ë©”ë‰´ ì„¤ì •ì—ì„œ í˜ì´ì§€ ìë™ ìƒì„±
    for category in MENU_CONFIG:
        for submenu in category['submenu']:
            cursor.execute("SELECT COUNT(*) FROM pages WHERE url = ?", (submenu['url'],))
            if cursor.fetchone()[0] == 0:
                cursor.execute(
                    "INSERT INTO pages (url, title, content) VALUES (?, ?, ?)",
                    (submenu['url'], submenu['title'], 
                     f"<h1>{submenu['title']}</h1><p>ì´ í˜ì´ì§€ì˜ ë‚´ìš©ì„ í¸ì§‘í•˜ì„¸ìš”.</p>")
                )
    
    conn.commit()
    conn.close()
    
    # ì™¸ë¶€ DB ì—°ë™ì´ í™œì„±í™”ëœ ê²½ìš° ë™ê¸°í™” ì‹œë„
    if db_config.external_db_enabled:
        sync_success = True
        
        # 1. í˜‘ë ¥ì‚¬ ë°ì´í„° ë™ê¸°í™”
        try:
            logging.info("í˜‘ë ¥ì‚¬ ë°ì´í„° ë™ê¸°í™” ì‹œì‘...")
            if not partner_manager.sync_partners_from_external_db():
                logging.warning("í˜‘ë ¥ì‚¬ ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨")
                sync_success = False
            else:
                logging.info("í˜‘ë ¥ì‚¬ ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logging.error(f"í˜‘ë ¥ì‚¬ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            sync_success = False
        
        # 2. ì‚¬ê³  ë°ì´í„° ë™ê¸°í™” (ACCIDENTS_QUERYê°€ ìˆì„ ë•Œë§Œ)
        try:
            if partner_manager.config.has_option('SQL_QUERIES', 'ACCIDENTS_QUERY'):
                logging.info("ì‚¬ê³  ë°ì´í„° ë™ê¸°í™” ì‹œì‘...")
                if partner_manager.sync_accidents_from_external_db():
                    logging.info("ì‚¬ê³  ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ")
                else:
                    logging.warning("ì‚¬ê³  ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨ - ë”ë¯¸ ë°ì´í„° ì‚¬ìš©")
            else:
                logging.info("ACCIDENTS_QUERY ë¯¸ì„¤ì • - ì‚¬ê³  ë°ì´í„°ëŠ” ë”ë¯¸ ì‚¬ìš©")
        except Exception as e:
            logging.warning(f"ì‚¬ê³  ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e} - ë”ë¯¸ ë°ì´í„° ì‚¬ìš©")
        
        # ë™ê¸°í™” ì‹¤íŒ¨ ì‹œ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        if not sync_success:
            logging.info("ì¼ë¶€ ë™ê¸°í™” ì‹¤íŒ¨ - ìƒ˜í”Œ ë°ì´í„°ë¡œ ëŒ€ì²´")
            init_sample_data()
    else:
        # ì™¸ë¶€ DBê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        init_sample_data()

def init_sample_data():
    """ì™¸ë¶€ DB ì—†ì„ ë•Œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    conn = partner_manager.db_config.get_sqlite_connection()
    cursor = conn.cursor()
    
    # ì´ë¯¸ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    try:
        cursor.execute("SELECT COUNT(*) FROM partners_cache")
        count = cursor.fetchone()[0]
        
        # permanent_workers ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        cursor.execute("PRAGMA table_info(partners_cache)")
        columns = [col[1] for col in cursor.fetchall()]
        
        # permanent_workers ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ì— ëœë¤ê°’ ì¶”ê°€
        if 'permanent_workers' not in columns:
            logging.info("permanent_workers ì»¬ëŸ¼ì´ ì—†ì–´ì„œ ê¸°ì¡´ ë°ì´í„°ì— ê°’ì„ ì¶”ê°€í•©ë‹ˆë‹¤")
            import random
            cursor.execute("SELECT business_number FROM partners_cache")
            existing_partners = cursor.fetchall()
            for partner in existing_partners:
                permanent_workers = random.randint(5, 500)
                cursor.execute("UPDATE partners_cache SET permanent_workers = ? WHERE business_number = ?", 
                             (permanent_workers, partner[0]))
            conn.commit()
            logging.info(f"ê¸°ì¡´ {len(existing_partners)}ê°œ í˜‘ë ¥ì‚¬ì— ìƒì‹œê·¼ë¡œì ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
        
        # ë°ì´í„°ê°€ ì¶©ë¶„íˆ ìˆìœ¼ë©´ ì¢…ë£Œ
        if count > 0:
            conn.close()
            return
    except Exception as e:
        logging.warning(f"ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    logging.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")
    
    import random
    random.seed(42)  # ê³ ì •ëœ ì‹œë“œ
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
    base_companies = [
        'ì‚¼ì„±ì „ì', 'LGì „ì', 'í˜„ëŒ€ìë™ì°¨', 'SKí•˜ì´ë‹‰ìŠ¤', 'POSCOí™€ë”©ìŠ¤',
        'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì‹ í•œê¸ˆìœµì§€ì£¼', 'í•œêµ­ì „ë ¥ê³µì‚¬', 'KT',
        'LGí™”í•™', 'í˜„ëŒ€ì¤‘ê³µì—…', 'í•œí™”ì†”ë£¨ì…˜', 'SKí…”ë ˆì½¤', 'ê¸°ì•„',
        'ë¡¯ë°ì¼€ë¯¸ì¹¼', 'S-Oil', 'GSì¹¼í…ìŠ¤', 'ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°', 'HDí˜„ëŒ€ì¤‘ê³µì—…'
    ]
    
    business_types_data = {
        'ì œì¡°ì—…': ['ì „ìì œí’ˆ', 'ìë™ì°¨', 'ê¸°ê³„', 'í™”í•™', 'ì„¬ìœ ', 'ì‹í’ˆ', 'ì˜ì•½í’ˆ', 'ì² ê°•', 'í”Œë¼ìŠ¤í‹±', 'ê¸°íƒ€ì œì¡°'],
        'ê±´ì„¤ì—…': ['ê±´ì¶•ê³µì‚¬', 'í† ëª©ê³µì‚¬', 'ì „ê¸°ê³µì‚¬', 'í†µì‹ ê³µì‚¬', 'ì„¤ë¹„ê³µì‚¬', 'ì¡°ê²½ê³µì‚¬', 'ì¸í…Œë¦¬ì–´', 'ê¸°íƒ€ê±´ì„¤'],
        'ITì—…': ['ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ', 'ì‹œìŠ¤í…œí†µí•©', 'ë°ì´í„°ë² ì´ìŠ¤', 'ë„¤íŠ¸ì›Œí¬', 'ë³´ì•ˆ', 'ê²Œì„ê°œë°œ', 'ì›¹ê°œë°œ', 'ëª¨ë°”ì¼ì•±'],
        'ì„œë¹„ìŠ¤ì—…': ['ì»¨ì„¤íŒ…', 'êµìœ¡', 'ì˜ë£Œ', 'ë²•ë¥ ', 'íšŒê³„', 'ì¸ì‚¬', 'ë§ˆì¼€íŒ…', 'ë””ìì¸', 'ì²­ì†Œ', 'ë³´ì•ˆì„œë¹„ìŠ¤'],
        'ìš´ìˆ˜ì—…': ['ìœ¡ìƒìš´ì†¡', 'í•´ìƒìš´ì†¡', 'í•­ê³µìš´ì†¡', 'ë¬¼ë¥˜', 'ì°½ê³ ', 'íƒë°°', 'ë Œí„°ì¹´', 'ê¸°íƒ€ìš´ì†¡'],
        'ìœ í†µì—…': ['ë„ë§¤', 'ì†Œë§¤', 'ì „ììƒê±°ë˜', 'ë°±í™”ì ', 'ë§ˆíŠ¸', 'í¸ì˜ì ', 'ì˜¨ë¼ì¸ì‡¼í•‘ëª°', 'ê¸°íƒ€ìœ í†µ'],
        'ê¸ˆìœµì—…': ['ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ì¹´ë“œ', 'ë¦¬ìŠ¤', 'íˆ¬ì', 'ìì‚°ê´€ë¦¬', 'í•€í…Œí¬'],
        'ì—ë„ˆì§€ì—…': ['ì „ë ¥', 'ê°€ìŠ¤', 'ì„ìœ ', 'ì‹ ì¬ìƒì—ë„ˆì§€', 'ì›ìë ¥', 'ì„íƒ„', 'ê¸°íƒ€ì—ë„ˆì§€']
    }
    
    business_types = list(business_types_data.keys())
    certifications = ['ISO 9001', 'ISO 14001', 'ISO 45001', 'KSì¸ì¦', 'GMP', 'HACCP', 'ì—†ìŒ']
    safety_ratings = ['Aë“±ê¸‰', 'Bë“±ê¸‰', 'Cë“±ê¸‰', 'Dë“±ê¸‰']
    products = ['ì „ìë¶€í’ˆ', 'ìë™ì°¨ë¶€í’ˆ', 'í™”í•™ì›ë£Œ', 'ê¸°ê³„ë¶€í’ˆ', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í†µì‹ ì¥ë¹„', 'ê±´ì„¤ìì¬', 'ì˜ë£Œê¸°ê¸°', 'ì‹í’ˆ', 'ê¸°íƒ€']
    
    # 203ê°œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    for i in range(203):
        if i < 20:
            company_name = f"{base_companies[i % len(base_companies)]}(ì£¼)"
            business_number = f"{100 + i:03d}81{random.randint(10000, 99999):05d}"
        else:
            company_name = f"í˜‘ë ¥ì—…ì²´{i-19:03d}(ì£¼)"
            business_number = f"{random.randint(100, 999)}81{random.randint(10000, 99999):05d}"
        
        representative = f"ëŒ€í‘œì{i+1:03d}"
        permanent_workers = random.randint(5, 500)  # ìƒì‹œê·¼ë¡œì ìˆ˜ (5ëª…~500ëª…)
        partner_class = random.choice(['-', 'A', 'B', 'C'])
        
        business_type_major = random.choice(business_types)
        minor_count = random.randint(1, 2)
        selected_minors = random.sample(business_types_data[business_type_major], min(minor_count, len(business_types_data[business_type_major])))
        business_type_minor = ', '.join(selected_minors)
        
        hazard_work_flag = random.choice(['O', 'X', ''])  # O: ìœ„í—˜ì‘ì—…, X: ë¹„ìœ„í—˜ì‘ì—…, '': ë¯¸ë¶„ë¥˜
        address = f"ì„œìš¸íŠ¹ë³„ì‹œ {random.choice(['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ì˜ë“±í¬êµ¬', 'ë§ˆí¬êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬'])} ìƒ˜í”Œë¡œ{random.randint(1, 999)}"
        average_age = random.randint(25, 55)  # í‰ê·  ì—°ë ¹
        annual_revenue = random.randint(1, 1000) * 100000000  # ì—°ë§¤ì¶œ (ì–µì› ë‹¨ìœ„)
        transaction_count = random.randint(1, 50)  # ê±°ë˜ ì°¨ìˆ˜
        
        cursor.execute('''
            INSERT INTO partners_cache (
                business_number, company_name, partner_class, business_type_major, 
                business_type_minor, hazard_work_flag, representative, address,
                average_age, annual_revenue, transaction_count, permanent_workers
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            business_number, company_name, partner_class, business_type_major,
            business_type_minor, hazard_work_flag, representative, address,
            average_age, annual_revenue, transaction_count, permanent_workers
        ))
        
        # ì¼ë¶€ í˜‘ë ¥ì‚¬ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìƒ˜í”Œ ì²¨ë¶€íŒŒì¼ ì¶”ê°€
        if i < 5:  # ì²˜ìŒ 5ê°œ í˜‘ë ¥ì‚¬ì—ë§Œ ì¶”ê°€
            # uploads í´ë”ì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë“¤ ì‚¬ìš©
            real_files = [
                ('sample_for_you_1755663410.xlsx', 'uploads/sample_for_you_1755663410.xlsx', 'ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼'),
                ('[Quick Guide] DSì‚¬ì—…ì¥ ë‚´ë°©ì‹ ì²­ v.03_1755666638.pdf', 'uploads/[Quick Guide] DSì‚¬ì—…ì¥ ë‚´ë°©ì‹ ì²­ v.03_1755666638.pdf', 'DSì‚¬ì—…ì¥ ê°€ì´ë“œ'),
                ('[Quick Guide] ìƒìƒí˜‘ë ¥í¬í„¸(PCMS) íšŒì›ê°€ì… v.02_1755674307.pdf', 'uploads/[Quick Guide] ìƒìƒí˜‘ë ¥í¬í„¸(PCMS) íšŒì›ê°€ì… v.02_1755674307.pdf', 'PCMS ê°€ì… ê°€ì´ë“œ')
            ]
            
            # í•˜ë‚˜ì˜ ì‹¤ì œ íŒŒì¼ë§Œ ì¶”ê°€ (í™•ì‹¤íˆ ë‹¤ìš´ë¡œë“œë˜ë„ë¡)
            file_info = real_files[i % len(real_files)]
            file_path = os.path.join(os.getcwd(), file_info[1])
            
            # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                cursor.execute('''
                    INSERT INTO partner_attachments (
                        business_number, file_name, file_path, file_size, description
                    ) VALUES (?, ?, ?, ?, ?)
                ''', (
                    business_number,
                    file_info[0],
                    file_path,  # ì „ì²´ ê²½ë¡œë¡œ ì €ì¥
                    file_size,
                    file_info[2]
                ))
    
    conn.commit()
    conn.close()
    logging.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ")

@app.before_request
def before_request():
    # ë°ì´í„° ë³µêµ¬ í˜ì´ì§€ëŠ” init_db ê±´ë„ˆë›°ê¸° (ë™ê¸°í™” ë°©ì§€)
    if request.path != '/data-recovery':
        init_db()

@app.route("/")
def index():
    # ëŒ€ì‹œë³´ë“œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ë‹¨ìˆœí™”)
    dashboard_config = {
        'url': db_config.config.get('DASHBOARD', 'DASHBOARD_URL', 
                                   fallback='https://your-dashboard.com'),
        'enabled': db_config.config.getboolean('DASHBOARD', 'DASHBOARD_ENABLED', 
                                              fallback=True)
    }
    return render_template("index.html", menu=MENU_CONFIG, dashboard_config=dashboard_config)

# ê°œë³„ ë¼ìš°íŠ¸ë“¤ì„ catch-all ë¼ìš°íŠ¸ë³´ë‹¤ ë¨¼ì € ì •ì˜
@app.route("/partner-standards")
def partner_standards_route():
    """í˜‘ë ¥ì‚¬ ê¸°ì¤€ì •ë³´ í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return partner_standards()

@app.route("/partner-change-request")
def partner_change_request_route():
    """ê¸°ì¤€ì •ë³´ ë³€ê²½ìš”ì²­ í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return partner_change_request()

@app.route("/partner-accident")
def partner_accident_route():
    """í˜‘ë ¥ì‚¬ ì‚¬ê³  í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return partner_accident()

@app.route("/data-recovery")
def data_recovery():
    """ë°ì´í„° ë³µêµ¬ í˜ì´ì§€"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    
    # ì‚­ì œëœ ì‚¬ê³  ì¡°íšŒ
    deleted_accidents_rows = conn.execute("""
        SELECT * FROM accidents_cache 
        WHERE is_deleted = 1
        ORDER BY accident_date DESC, accident_number DESC
    """).fetchall()
    
    deleted_accidents = [dict(row) for row in deleted_accidents_rows]
    
    # ì‚­ì œëœ í˜‘ë ¥ì‚¬ ì¡°íšŒ
    deleted_partners_rows = conn.execute("""
        SELECT * FROM partners_cache 
        WHERE is_deleted = 1
        ORDER BY company_name
    """).fetchall()
    
    deleted_partners = [dict(row) for row in deleted_partners_rows]
    conn.close()
    
    return render_template('data-recovery.html', 
                         deleted_accidents=deleted_accidents,
                         deleted_partners=deleted_partners,
                         menu=MENU_CONFIG,
                         active_slug='data-recovery')

def partner_standards():
    """í˜‘ë ¥ì‚¬ ê¸°ì¤€ì •ë³´ í˜ì´ì§€"""
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 10, type=int)
    
    # ê²€ìƒ‰ ì¡°ê±´
    filters = {
        'company_name': request.args.get('company_name', '').strip(),
        'business_number': request.args.get('business_number', '').strip(),
        'business_type_major': request.args.get('business_type_major', '').strip(),
        'business_type_minor': request.args.get('business_type_minor', '').strip(),
        'workers_min': request.args.get('workers_min', type=int),
        'workers_max': request.args.get('workers_max', type=int)
    }
    
    # ìƒˆë¡œìš´ ë°ì´í„° ë§¤ë‹ˆì €ë¥¼ í†µí•´ í˜‘ë ¥ì‚¬ ëª©ë¡ ì¡°íšŒ
    partners, total_count = partner_manager.get_all_partners(
        page=page, 
        per_page=per_page, 
        filters=filters
    )
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´
    class Pagination:
        def __init__(self, page, per_page, total_count):
            self.page = page
            self.per_page = per_page
            self.total_count = total_count
            self.pages = math.ceil(total_count / per_page)
            self.has_prev = page > 1
            self.prev_num = page - 1 if self.has_prev else None
            self.has_next = page < self.pages
            self.next_num = page + 1 if self.has_next else None
        
        def iter_pages(self, window_size=10):
            # í˜„ì¬ í˜ì´ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 10ê°œ í˜ì´ì§€ ìœˆë„ìš° ìƒì„±
            start = ((self.page - 1) // window_size) * window_size + 1
            end = min(start + window_size - 1, self.pages)
            for num in range(start, end + 1):
                yield num
        
        def get_window_info(self, window_size=10):
            # í˜„ì¬ ìœˆë„ìš°ì˜ ì‹œì‘ê³¼ ë í˜ì´ì§€
            start = ((self.page - 1) // window_size) * window_size + 1
            end = min(start + window_size - 1, self.pages)
            has_prev_window = start > 1
            has_next_window = end < self.pages
            prev_window_start = max(1, start - window_size)
            next_window_start = min(end + 1, self.pages)
            return {
                'start': start,
                'end': end,
                'has_prev_window': has_prev_window,
                'has_next_window': has_next_window,
                'prev_window_start': prev_window_start,
                'next_window_start': next_window_start
            }
    
    pagination = Pagination(page, per_page, total_count)
    
    return render_template('partner-standards.html',
                         partners=partners,
                         total_count=total_count,
                         pagination=pagination,
                         menu=MENU_CONFIG)


def partner_change_request():
    """ê¸°ì¤€ì •ë³´ ë³€ê²½ìš”ì²­ í˜ì´ì§€"""
    # ë”ë¯¸ í˜ì´ì§€ë„¤ì´ì…˜ ê°ì²´ ìƒì„± (ì‹¤ì œ ë°ì´í„° ë¡œë”© ì‹œ êµì²´ ì˜ˆì •)
    class DummyPagination:
        def __init__(self):
            self.pages = 1
    
    pagination = DummyPagination()
    return render_template('partner-change-request.html', menu=MENU_CONFIG, pagination=pagination, total_count=0)


def partner_accident():
    """í˜‘ë ¥ì‚¬ ì‚¬ê³  í˜ì´ì§€"""
    
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 10, type=int)
    
    # ê²€ìƒ‰ ì¡°ê±´
    filters = {
        'company_name': request.args.get('company_name', '').strip(),
        'business_number': request.args.get('business_number', '').strip(),
        'accident_date_start': request.args.get('accident_date_start', '').strip(),
        'accident_date_end': request.args.get('accident_date_end', '').strip()
    }
    
    # Phase 1: ë™ì  ì»¬ëŸ¼ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    dynamic_columns_rows = conn.execute("""
        SELECT * FROM accident_column_config 
        WHERE is_active = 1 
        ORDER BY column_order
    """).fetchall()
    # Row ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
    dynamic_columns = [dict(row) for row in dynamic_columns_rows]
    
    # ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼ì— ëŒ€í•´ ì½”ë“œ-ê°’ ë§¤í•‘ ì •ë³´ ì¶”ê°€
    for col in dynamic_columns:
        if col['column_type'] == 'dropdown':
            col['code_mapping'] = get_dropdown_options_for_display(col['column_key'])
    
    # ì‚¬ê³  ë°ì´í„° ì¡°íšŒ (ìš´ì˜ í™˜ê²½ ê³ ë ¤)
    import random
    import datetime
    
    # ì‚¬ê³  ë°ì´í„° ì¡°íšŒ - ë‹¨ìˆœí™”
    all_accidents = []
    
    
    # 1. í•­ìƒ ë¡œì»¬ DBì—ì„œ ë¨¼ì € ì¡°íšŒ (ë“±ë¡ëœ ì‚¬ê³ )  
    try:
        # accident_datetime ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(accidents_cache)")
        columns = [col[1] for col in cursor.fetchall()]
        
        if 'accident_datetime' not in columns:
            cursor.execute("ALTER TABLE accidents_cache ADD COLUMN accident_datetime TEXT")
            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë‚ ì§œì™€ ì‹œê°„ ì¡°í•©)
            cursor.execute("""
                UPDATE accidents_cache 
                SET accident_datetime = 
                    CASE 
                        WHEN accident_date IS NOT NULL AND accident_time IS NOT NULL 
                        THEN accident_date || ' ' || accident_time
                        WHEN accident_date IS NOT NULL 
                        THEN accident_date || ' 00:00'
                        ELSE datetime('now', 'localtime')
                    END
                WHERE accident_datetime IS NULL
            """)
            conn.commit()
            logging.info("accident_datetime ì»¬ëŸ¼ ì¶”ê°€ ë° ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        local_accidents_rows = conn.execute("""
            SELECT * FROM accidents_cache 
            WHERE is_deleted = 0 OR is_deleted IS NULL
            ORDER BY 
                CASE 
                    WHEN accident_datetime IS NOT NULL AND accident_datetime != '' 
                    THEN accident_datetime 
                    ELSE COALESCE(accident_date, '1900-01-01') || ' 00:00' 
                END DESC, 
                accident_number DESC
        """).fetchall()
        
        logging.info(f"ë¡œì»¬ DBì—ì„œ {len(local_accidents_rows)}ê°œ ì‚¬ê³  ì¡°íšŒë¨")
        
        for row in local_accidents_rows:
            accident = dict(row)
            # ID í™•ì¸ ë° ì„¤ì •
            if 'id' not in accident or not accident['id']:
                accident['id'] = len(all_accidents) + 1000  # ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ 1000ë¶€í„° ì‹œì‘
            # í•„ìˆ˜ í•„ë“œ ì±„ìš°ê¸°
            accident['accident_name'] = accident.get('accident_name') or f"ì‚¬ê³ _{accident['accident_number']}"
            accident['custom_data'] = accident.get('custom_data', '{}')
            
            # ì›¹ í‘œì‹œìš© í•„ìˆ˜ í•„ë“œë“¤ ì±„ìš°ê¸°
            accident['accident_grade'] = accident.get('accident_grade') or accident.get('injury_level', 'ì¼ë°˜')
            accident['accident_type'] = accident.get('accident_type', 'ê¸°íƒ€')
            accident['disaster_type'] = accident.get('disaster_type', 'ì¼ë°˜ì‚¬ê³ ')
            accident['disaster_form'] = accident.get('disaster_form', 'ê¸°íƒ€')
            accident['workplace'] = accident.get('workplace', 'ë¯¸ë¶„ë¥˜')
            accident['building'] = accident.get('building', 'ë¯¸ë¶„ë¥˜')
            accident['floor'] = accident.get('floor', 'ë¯¸ë¶„ë¥˜')
            accident['detail_location'] = accident.get('detail_location', accident.get('accident_location', 'ë¯¸ë¶„ë¥˜'))
            accident['time'] = accident.get('time', 'ë¯¸ë¶„ë¥˜')
            accident['day_of_week'] = accident.get('day_of_week', 'ë¯¸ë¶„ë¥˜')
            accident['accident_content'] = accident.get('accident_content', accident.get('accident_description', 'ë‚´ìš© ì—†ìŒ'))
            accident['responsible_company_1'] = accident.get('responsible_company_1', 'ì§ì ‘ë“±ë¡')
            accident['responsible_company_1_business_number'] = accident.get('responsible_company_1_business_number', accident.get('business_number', 'DIRECT-ENTRY'))
            accident['responsible_company_2'] = accident.get('responsible_company_2')
            accident['responsible_company_2_business_number'] = accident.get('responsible_company_2_business_number')
            
            all_accidents.append(accident)
        
        logging.info(f"ë¡œì»¬ ì‚¬ê³  ì¶”ê°€ ì™„ë£Œ: {len(all_accidents)}ê°œ")
    except Exception as e:
        logging.error(f"ë¡œì»¬ ì‚¬ê³  ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        logging.error(traceback.format_exc())
    
    
    # 2. ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë”ë¯¸ ë°ì´í„° ì¶”ê°€ (ë¡œì»¬ ì‚¬ê³  ë’¤ì—)
    if not db_config.external_db_enabled:
        import json
        
        # ë”ë¯¸ ë°ì´í„°ë¥¼ ì„ì‹œ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
        dummy_accidents = []
        for i in range(50):  # 50ê°œ ë”ë¯¸ ë°ì´í„°
            # ì‚¬ê³ ë²ˆí˜¸ ìƒì„±: K + ì—°ì›”ì¼ + ìˆœì„œ(3ìë¦¬)
            months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
            days = [1, 5, 10, 15, 20, 25]
            accident_date_fixed = f'2024-{months[i % 12]:02d}-{days[i % 6]:02d}'
            accident_number = f'K{accident_date_fixed.replace("-", "")}{i+1:03d}'
            
            # ê³ ì •ëœ ê°’ë“¤
            grades = ['ê²½ë¯¸', 'ì¤‘ëŒ€', 'ì¹˜ëª…']
            types = ['ì¶”ë½', 'í˜‘ì°©', 'ì ˆë‹¨', 'í™”ì¬']
            disaster_types = ['ì•ˆì „ì‚¬ê³ ', 'ë³´ê±´ì‚¬ê³ ']
            disaster_forms = ['ë‚™í•˜', 'ì¶©ëŒ', 'ì „ë„']
            days_of_week = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
            
            dummy_accident = {
                'id': i + 1,
                'accident_number': accident_number,
                'accident_name': f'ì‚¬ê³ ì‚¬ë¡€{i+1:03d}',
                'accident_date': accident_date_fixed,
                'accident_grade': grades[i % 3],
                'accident_type': types[i % 4],
                'disaster_type': disaster_types[i % 2],
                'disaster_form': disaster_forms[i % 3],
                'workplace': f'ì‚¬ì—…ì¥{(i % 5) + 1}',
                'building': f'ê±´ë¬¼{(i % 10) + 1}',
                'floor': f'{(i % 20) + 1}ì¸µ',
                'detail_location': f'ìƒì„¸ìœ„ì¹˜{i+1:03d}',
                'time': f'{9 + (i % 10):02d}:{(i * 5) % 60:02d}',
                'day_of_week': days_of_week[i % 7],
                'accident_content': f'ì‚¬ê³ ë‚´ìš©{i+1}',
                'responsible_company_1': f'í˜‘ë ¥ì‚¬{(i % 20) + 1}',
                'responsible_company_1_business_number': f'{1000000000 + i * 11111}',
                'responsible_company_2': f'í˜‘ë ¥ì‚¬{(i % 15) + 1}' if i % 3 == 0 else None,
                'responsible_company_2_business_number': f'{2000000000 + i * 22222}' if i % 3 == 0 else None,
            }
            
            # ë™ì  ì»¬ëŸ¼ ë°ì´í„° ì¶”ê°€
            custom_data = {}
            for col in dynamic_columns:
                col_key = col['column_key']
                col_type = col['column_type']
                
                if col_type == 'dropdown':
                    options = json.loads(col['dropdown_options']) if col['dropdown_options'] else []
                    custom_data[col_key] = options[i % len(options)] if options else f'{col_key}-ê°’{i+1}'
                elif col_type == 'date':
                    custom_data[col_key] = f'2025-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}'
                elif col_type == 'popup_person':
                    custom_data[col_key] = {'name': f'ë‹´ë‹¹ì{i+1}', 'department': f'ë¶€ì„œ{i % 5 + 1}'}
                elif col_type == 'popup_company':
                    custom_data[col_key] = {'name': f'ì—…ì²´{i+1}', 'business_number': f'{3000000000 + i * 33333}'}
                else:
                    custom_data[col_key] = f'{col["column_name"]}-ê°’{i+1}'
            
            dummy_accident['custom_data'] = json.dumps(custom_data, ensure_ascii=False)
            dummy_accidents.append(dummy_accident)
        
        # ë¡œì»¬ ì‚¬ê³  ë’¤ì— ë”ë¯¸ ì‚¬ê³  ì¶”ê°€
        all_accidents.extend(dummy_accidents)
        
        logging.info(f"ë”ë¯¸ ë°ì´í„° 50ê°œ ì¶”ê°€ë¨")
    
    print(f"[DEBUG] ì „ì²´ ì‚¬ê³  ê°œìˆ˜: {len(all_accidents)}", flush=True)
    logging.info(f"ì „ì²´ ì‚¬ê³  ê°œìˆ˜: {len(all_accidents)}")
    
    filtered_accidents = all_accidents
    
    if filters['company_name']:
        filtered_accidents = [a for a in filtered_accidents if filters['company_name'].lower() in a['responsible_company_1'].lower()]
    
    if filters['business_number']:
        filtered_accidents = [a for a in filtered_accidents if filters['business_number'] in str(a['responsible_company_1_business_number'])]
    
    if filters['accident_date_start']:
        filtered_accidents = [a for a in filtered_accidents if a['accident_date'] >= filters['accident_date_start']]
    
    if filters['accident_date_end']:
        filtered_accidents = [a for a in filtered_accidents if a['accident_date'] <= filters['accident_date_end']]
    
    total_count = len(filtered_accidents)
    
    # í˜ì´ì§€ë„¤ì´ì…˜
    start = (page - 1) * per_page
    end = start + per_page
    accidents = filtered_accidents[start:end]
    
    
    # ë”•ì…”ë„ˆë¦¬ë¥¼ ê°ì²´ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜
    class DictAsAttr:
        def __init__(self, d):
            for k, v in d.items():
                setattr(self, k, v)
    
    accidents = [DictAsAttr(a) for a in accidents]
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ (partner_standardsì™€ ë™ì¼í•œ í´ë˜ìŠ¤ ì‚¬ìš©)
    class Pagination:
        def __init__(self, page, per_page, total_count):
            self.page = page
            self.per_page = per_page
            self.total_count = total_count
            self.pages = math.ceil(total_count / per_page)
            self.has_prev = page > 1
            self.prev_num = page - 1 if self.has_prev else None
            self.has_next = page < self.pages
            self.next_num = page + 1 if self.has_next else None
        
        def iter_pages(self, window_size=10):
            start = ((self.page - 1) // window_size) * window_size + 1
            end = min(start + window_size - 1, self.pages)
            for num in range(start, end + 1):
                yield num
        
        def get_window_info(self, window_size=10):
            start = ((self.page - 1) // window_size) * window_size + 1
            end = min(start + window_size - 1, self.pages)
            has_prev_window = start > 1
            has_next_window = end < self.pages
            prev_window_start = max(1, start - window_size)
            next_window_start = min(end + 1, self.pages)
            return {
                'start': start,
                'end': end,
                'has_prev_window': has_prev_window,
                'has_next_window': has_next_window,
                'prev_window_start': prev_window_start,
                'next_window_start': next_window_start
            }
    
    pagination = Pagination(page, per_page, total_count)
    
    # DB ì—°ê²° ë‹«ê¸°
    conn.close()
    
    # ì½”ë“œë¥¼ ê°’ìœ¼ë¡œ ë³€í™˜ (í‘œì‹œìš©)
    for accident in accidents:
        # DictAsAttr ê°ì²´ ì²˜ë¦¬ë¥¼ ìœ„í•´ hasattr ì‚¬ìš©
        if hasattr(accident, 'custom_data') and accident.custom_data:
            try:
                custom_data = json.loads(accident.custom_data)
                for col in dynamic_columns:
                    if col['column_type'] == 'dropdown' and col['column_key'] in custom_data:
                        code = custom_data[col['column_key']]
                        if code:
                            # ì½”ë“œë¥¼ ê°’ìœ¼ë¡œ ë³€í™˜
                            custom_data[col['column_key']] = convert_code_to_value(col['column_key'], code)
                accident.custom_data = json.dumps(custom_data, ensure_ascii=False)
            except Exception as e:
                logging.error(f"ì½”ë“œ ë³€í™˜ ì˜¤ë¥˜: {e}")
    
    # ë””ë²„ê¹… ë¡œê·¸
    logging.info(f"partner_accident: ì „ì²´ {len(all_accidents)}ê°œ, í•„í„°ë§ {total_count}ê°œ, í‘œì‹œ {len(accidents)}ê°œ")
    
    return render_template('partner-accident.html',
                         accidents=accidents,
                         total_count=total_count,
                         pagination=pagination,
                         dynamic_columns=dynamic_columns,  # Phase 1: ë™ì  ì»¬ëŸ¼ ì •ë³´ ì „ë‹¬
                         menu=MENU_CONFIG)

# í¸ì§‘ ê¸°ëŠ¥ ì™„ì „ ì œê±° - ì‹¬í”Œí•¨ì„ ìœ„í•´

@app.route("/partner/<business_number>")
@app.route("/partner-detail/<business_number>")
def partner_detail(business_number):
    """í˜‘ë ¥ì‚¬ ìƒì„¸ì •ë³´ í˜ì´ì§€"""
    logging.info(f"í˜‘ë ¥ì‚¬ ìƒì„¸ ì •ë³´ ì¡°íšŒ: {business_number}")
    
    # ìƒˆë¡œìš´ ë°ì´í„° ë§¤ë‹ˆì €ë¥¼ í†µí•´ í˜‘ë ¥ì‚¬ ì •ë³´ ì¡°íšŒ
    partner = partner_manager.get_partner_by_business_number(business_number)
    
    if not partner:
        logging.warning(f"í˜‘ë ¥ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {business_number}")
        return "í˜‘ë ¥ì‚¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
    
    # ì²¨ë¶€íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    conn = partner_manager.db_config.get_sqlite_connection()
    conn.row_factory = sqlite3.Row
    attachments = conn.execute("""
        SELECT * FROM partner_attachments 
        WHERE business_number = ? 
        ORDER BY upload_date DESC
    """, (business_number,)).fetchall()
    conn.close()
    
    logging.info(f"í˜‘ë ¥ì‚¬ {business_number} ({partner['company_name']}) ìƒì„¸ í˜ì´ì§€ ë¡œë“œ - ì²¨ë¶€íŒŒì¼ {len(attachments)}ê°œ")
    
    # íŒì—… ëª¨ë“œì¸ì§€ í™•ì¸
    is_popup = request.args.get('popup') == '1'
    
    return render_template('partner-detail.html', 
                         partner=partner, 
                         attachments=attachments,
                         menu=MENU_CONFIG, 
                         is_popup=is_popup,
                         board_type='partner')  # ê²Œì‹œíŒ íƒ€ì… ì „ë‹¬

@app.route("/accident-detail/<int:accident_id>")
def accident_detail(accident_id):
    """ì‚¬ê³  ìƒì„¸ì •ë³´ í˜ì´ì§€"""
    print(f"[DEBUG] accident_detail í•¨ìˆ˜ í˜¸ì¶œë¨: ID={accident_id}", flush=True)
    logging.info(f"ì‚¬ê³  ìƒì„¸ ì •ë³´ ì¡°íšŒ: {accident_id}")
    
    # ë”ë¯¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì‚¬ê³  ì°¾ê¸° (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
    import random
    
    # ë”ë¯¸ ì‚¬ê³  ë°ì´í„° (partner_accident í•¨ìˆ˜ì™€ ë™ì¼í•œ ë°ì´í„° ìƒì„±)
    dummy_accidents = []
    for i in range(50):
        # ì‚¬ê³ ë²ˆí˜¸ ìƒì„±: K + ì—°ì›”ì¼ + ìˆœì„œ(3ìë¦¬) - ê³ ì •ëœ ê°’
        months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
        days = [1, 5, 10, 15, 20, 25]
        accident_date_fixed = f'2024-{months[i % 12]:02d}-{days[i % 6]:02d}'
        accident_number = f'K{accident_date_fixed.replace("-", "")}{i+1:03d}'
        
        # ê³ ì •ëœ ê°’ë“¤ë¡œ ë³€ê²½
        grades = ['ê²½ë¯¸', 'ì¤‘ëŒ€', 'ì¹˜ëª…']
        types = ['ì¶”ë½', 'í˜‘ì°©', 'ì ˆë‹¨', 'í™”ì¬']
        disaster_types = ['ì•ˆì „ì‚¬ê³ ', 'ë³´ê±´ì‚¬ê³ ']
        disaster_forms = ['ë‚™í•˜', 'ì¶©ëŒ', 'ì „ë„']
        days_of_week = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        
        # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€
        major_categories = ['ì œì¡°ì—…', 'ê±´ì„¤ì—…', 'ITì—…', 'ì„œë¹„ìŠ¤ì—…', 'ìš´ìˆ˜ì—…']
        location_categories = ['ì‚¬ë¬´ì‹¤', 'ìƒì‚°í˜„ì¥', 'ì°½ê³ ', 'ì•¼ì™¸', 'ê¸°íƒ€']
        
        dummy_accidents.append({
            'id': i + 1,
            'accident_number': accident_number,
            'accident_name': f'ì‚¬ê³ ì‚¬ë¡€{i+1:03d}',
            'accident_date': accident_date_fixed,
            'accident_grade': grades[i % 3],
            'major_category': major_categories[i % 5],  # ëŒ€ë¶„ë¥˜ ì¶”ê°€
            'accident_type': types[i % 4],
            'disaster_type': disaster_types[i % 2],
            'disaster_form': disaster_forms[i % 3],
            'injury_form': disaster_forms[i % 3],  # ì¬í•´í˜•íƒœ
            'injury_type': disaster_types[i % 2],  # ì¬í•´ìœ í˜•
            'workplace': f'ì‚¬ì—…ì¥{(i % 5) + 1}',
            'building': f'ê±´ë¬¼{(i % 10) + 1}',
            'floor': f'{(i % 20) + 1}ì¸µ',
            'location_category': location_categories[i % 5],  # ì¥ì†Œêµ¬ë¶„ ì¶”ê°€
            'location_detail': f'ìƒì„¸ìœ„ì¹˜{i+1:03d}',  # ì„¸ë¶€ì¥ì†Œ
            'detail_location': f'ìƒì„¸ìœ„ì¹˜{i+1:03d}',
            'report_date': accident_date_fixed,  # ë“±ë¡ì¼ ì¶”ê°€
            'accident_time': f'{9 + (i % 10):02d}:{(i * 5) % 60:02d}',  # ì‹œê°„ -> accident_timeìœ¼ë¡œ ë³€ê²½
            'time': f'{9 + (i % 10):02d}:{(i * 5) % 60:02d}',
            'day_of_week': days_of_week[i % 7],
            'accident_content': f'ì‚¬ê³ ë‚´ìš©{i+1}ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤.',
            'business_number': f'{1000000000 + i * 11111}',  # ì‚¬ì—…ìë²ˆí˜¸ ì¶”ê°€
            'responsible_company_1': f'í˜‘ë ¥ì‚¬{(i % 20) + 1}',
            'responsible_company_1_business_number': f'{1000000000 + i * 11111}',
            'responsible_company_2': f'í˜‘ë ¥ì‚¬{(i % 15) + 1}' if i % 3 == 0 else None,
            'responsible_company_2_business_number': f'{2000000000 + i * 22222}' if i % 3 == 0 else None,
        })
    
    # DBì—ì„œ ì‹¤ì œ ì‚¬ê³  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    conn = sqlite3.connect(DB_PATH, timeout=30.0)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # accidents_cacheì—ì„œ ë¨¼ì € ì°¾ê¸°
    cursor.execute("""
        SELECT * FROM accidents_cache 
        WHERE id = ? OR accident_number = ?
        LIMIT 1
    """, (accident_id, f'K{accident_id}'))
    
    accident = cursor.fetchone()
    
    # ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°ì—ì„œ ì°¾ê¸°
    if not accident:
        for acc in dummy_accidents:
            if acc['id'] == accident_id:
                accident = dict(acc)
                break
    else:
        accident = dict(accident)  # Rowë¥¼ dictë¡œ ë³€í™˜
    
    if not accident:
        logging.warning(f"ì‚¬ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {accident_id}")
        conn.close()
        return "ì‚¬ê³  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
    
    # accident_details í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS accident_details (
            accident_number TEXT PRIMARY KEY,
            detailed_content TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # accident_details í…Œì´ë¸”ì—ì„œ ìƒì„¸ë‚´ìš© ì¡°íšŒ
    cursor.execute("SELECT detailed_content FROM accident_details WHERE accident_number = ?", (accident['accident_number'],))
    detail_row = cursor.fetchone()
    if detail_row:
        accident['detailed_content'] = detail_row['detailed_content']
    else:
        accident['detailed_content'] = ''
    
    # accident_attachments í…Œì´ë¸”ë„ ìƒì„±
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS accident_attachments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            accident_number TEXT,
            file_name TEXT NOT NULL,
            file_path TEXT NOT NULL,
            file_size INTEGER,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # ì²¨ë¶€íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    attachments = cursor.execute("""
        SELECT * FROM accident_attachments 
        WHERE accident_number = ? 
        ORDER BY created_at DESC
    """, (accident['accident_number'],)).fetchall()
    
    # Phase 2: ë™ì  ì»¬ëŸ¼ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ì¶”ê°€ì •ë³´ ì„¹ì…˜ìš© - ê¸°ë³¸ì •ë³´ í•„ë“œ ì œì™¸)
    # ê¸°ë³¸ì •ë³´ ì„¹ì…˜ì— ì´ë¯¸ í‘œì‹œë˜ëŠ” í•„ë“œë“¤ì€ ì œì™¸
    basic_info_fields = [
        'accident_number', 'accident_name', 'workplace', 'accident_grade',
        'major_category', 'injury_form', 'injury_type', 'accident_date',
        'day_of_week', 'report_date', 'building', 'floor',
        'location_category', 'location_detail'
    ]
    
    dynamic_columns_rows = conn.execute("""
        SELECT * FROM accident_column_config 
        WHERE is_active = 1 
        AND column_key NOT IN ({})
        ORDER BY column_order
    """.format(','.join(['?'] * len(basic_info_fields))), basic_info_fields).fetchall()
    
    # Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    dynamic_columns = [dict(row) for row in dynamic_columns_rows]
    
    conn.close()
    
    # ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼ì— ëŒ€í•´ ì½”ë“œ-ê°’ ë§¤í•‘ ì ìš© (ë“±ë¡ í˜ì´ì§€ì™€ ë™ì¼í•œ ë¡œì§)
    for col in dynamic_columns:
        if col['column_type'] == 'dropdown':
            # ì½”ë“œ-ê°’ ë§¤í•‘ ë°©ì‹ìœ¼ë¡œ ì˜µì…˜ ê°€ì ¸ì˜¤ê¸°
            code_options = get_dropdown_options_for_display(col['column_key'])
            if code_options:
                # ìƒˆë¡œìš´ ë°©ì‹ì˜ ì˜µì…˜ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                col['dropdown_options_mapped'] = code_options
                logging.info(f"  - {col['column_name']} ({col['column_key']}): ì½”ë“œ-ê°’ ë§¤í•‘ {len(code_options)}ê°œ ì˜µì…˜")
            else:
                # ê¸°ì¡´ JSON ë°©ì‹ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
                col['dropdown_options_mapped'] = None
    
    # ë”•ì…”ë„ˆë¦¬ë¥¼ ê°ì²´ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜ (None ê°’ ì²˜ë¦¬ ê°œì„ )
    class DictAsAttr:
        def __init__(self, d):
            self._data = d
            for k, v in d.items():
                setattr(self, k, v if v is not None else '')
        
        def __getattr__(self, name):
            # ì†ì„±ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
            return self._data.get(name, '')
    
    # custom_data íŒŒì‹±
    import json
    custom_data = {}
    if 'custom_data' in accident and accident['custom_data']:
        try:
            custom_data = json.loads(accident['custom_data'])
            logging.info(f"Loaded custom_data: {custom_data}")
        except Exception as e:
            logging.error(f"Error parsing custom_data: {e}")
            custom_data = {}
    
    # ë””ë²„ê¹…: ì‚¬ê³  ë°ì´í„° í™•ì¸
    logging.info(f"ì‚¬ê³  ë°ì´í„°: {accident}")
    logging.info(f"accident_number: {accident.get('accident_number')}")
    logging.info(f"accident_name: {accident.get('accident_name')}")
    logging.info(f"accident_grade: {accident.get('accident_grade')}")
    logging.info(f"major_category: {accident.get('major_category')}")
    logging.info(f"injury_form: {accident.get('injury_form')}")
    logging.info(f"injury_type: {accident.get('injury_type')}")
    
    accident = DictAsAttr(accident)
    
    logging.info(f"ì‚¬ê³  {accident_id} ({accident.accident_name}) ìƒì„¸ í˜ì´ì§€ ë¡œë“œ")
    
    # íŒì—… ëª¨ë“œì¸ì§€ í™•ì¸
    is_popup = request.args.get('popup') == '1'
    
    # í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ í™•ì¸ (ë””ë²„ê¹…)
    import os
    template_path = os.path.join(app.template_folder, 'accident-detail.html')
    print(f"[DEBUG] ë Œë”ë§í•  í…œí”Œë¦¿ ê²½ë¡œ: {template_path}", flush=True)
    print(f"[DEBUG] í…œí”Œë¦¿ íŒŒì¼ ì¡´ì¬: {os.path.exists(template_path)}", flush=True)
    if os.path.exists(template_path):
        with open(template_path, 'r', encoding='utf-8') as f:
            first_100_lines = f.readlines()[:100]
            for i, line in enumerate(first_100_lines):
                if 'ê¸°ë³¸ì •ë³´' in line or 'ì‚¬ê³ ë²ˆí˜¸' in line or 'ëŒ€ë¶„ë¥˜' in line:
                    print(f"[DEBUG] í…œí”Œë¦¿ ë¼ì¸ {i+1}: {line.strip()}", flush=True)
    
    return render_template('accident-detail.html', 
                         accident=accident,
                         attachments=attachments,
                         dynamic_columns=dynamic_columns,  # ë™ì  ì»¬ëŸ¼ ì •ë³´
                         custom_data=custom_data,  # ê¸°ì¡´ ë°ì´í„°
                         menu=MENU_CONFIG, 
                         is_popup=is_popup,
                         board_type='accident')  # ê²Œì‹œíŒ íƒ€ì… ì „ë‹¬

def get_dropdown_options_for_display(column_key):
    """ë“œë¡­ë‹¤ìš´ ì˜µì…˜ì„ ì½”ë“œ-ê°’ ë§¤í•‘ ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        # í™œì„±í™”ëœ ì½”ë“œ ëª©ë¡ ì¡°íšŒ
        codes = conn.execute("""
            SELECT option_code, option_value 
            FROM dropdown_option_codes
            WHERE column_key = ? AND is_active = 1
            ORDER BY display_order
        """, (column_key,)).fetchall()
        
        logging.info(f"[DEBUG] get_dropdown_options_for_display({column_key}): {len(codes) if codes else 0}ê°œ í–‰ ì¡°íšŒë¨")
        if codes:
            for c in codes:
                logging.info(f"  - {c['option_code']}: {c['option_value']}")
        
        conn.close()
        
        if codes:
            # ğŸ” ë°©íƒ„: ë§Œì•½ 'ë‹¨ 1í–‰'ì´ê³  ê·¸ ê°’ì´ JSON ë°°ì—´ ë¬¸ìì—´ì´ë©´ ë°”ë¡œ ë¶„í•´í•´ì„œ ë°˜í™˜
            if len(codes) == 1:
                v = codes[0]['option_value']
                if isinstance(v, str):
                    s = v.strip()
                    if s.startswith('[') and s.endswith(']'):
                        try:
                            arr = json.loads(s)
                            if isinstance(arr, list):
                                # ê²½ê³ ë¥¼ ë””ë²„ê·¸ ë ˆë²¨ë¡œ ë³€ê²½ (ìš´ì˜ í™˜ê²½ì—ì„œëŠ” í‘œì‹œë˜ì§€ ì•ŠìŒ)
                                logging.debug(
                                    f"[{column_key}] option_valueê°€ ë°°ì—´ ë¬¸ìì—´ë¡œ ì €ì¥ë¨. ëŸ°íƒ€ì„ ë¶„í•´ ì²˜ë¦¬. "
                                    f"ì›ë³¸={v} (len={len(arr)})"
                                )
                                return [
                                    {'code': f"{column_key.upper()}_{i+1:03d}", 'value': str(item)}
                                    for i, item in enumerate(arr)
                                ]
                        except Exception as e:
                            logging.error(f"[{column_key}] ë°°ì—´ ë¬¸ìì—´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # ì •ìƒ ì¼€ì´ìŠ¤
            return [{'code': row['option_code'], 'value': row['option_value']} for row in codes]
        else:
            return None
    except:
        return None

def convert_code_to_value(column_key, code):
    """ì½”ë“œë¥¼ í‘œì‹œ ê°’ìœ¼ë¡œ ë³€í™˜"""
    if not code:
        return code
    
    # DROPDOWN_MAPPINGS ì‚¬ìš©
    if column_key in DROPDOWN_MAPPINGS:
        return DROPDOWN_MAPPINGS[column_key].get(code, code)
    
    # ë§¤í•‘ì´ ì—†ìœ¼ë©´ DB ì¡°íšŒ ì‹œë„
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ê°’ ì¡°íšŒ (ë¹„í™œì„±í™”ëœ ê²ƒë„ í¬í•¨ - ê¸°ì¡´ ë°ì´í„° í‘œì‹œìš©)
        result = cursor.execute("""
            SELECT option_value 
            FROM dropdown_option_codes
            WHERE column_key = ? AND option_code = ?
        """, (column_key, code)).fetchone()
        
        conn.close()
        
        if result:
            return result[0]
        else:
            # ë§¤í•‘ì´ ì—†ìœ¼ë©´ ì›ë³¸ ê°’ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
            return code
    except:
        return code

def convert_accident_codes_to_values(accident_data, dynamic_columns):
    """ì‚¬ê³  ë°ì´í„°ì˜ ì½”ë“œë¥¼ í‘œì‹œ ê°’ìœ¼ë¡œ ì¼ê´„ ë³€í™˜"""
    if not accident_data or not accident_data.get('custom_data'):
        return accident_data
    
    try:
        custom_data = json.loads(accident_data['custom_data'])
        
        for col in dynamic_columns:
            if col['column_type'] == 'dropdown' and col['column_key'] in custom_data:
                code = custom_data[col['column_key']]
                if code:
                    # ì½”ë“œë¥¼ ê°’ìœ¼ë¡œ ë³€í™˜
                    custom_data[col['column_key']] = convert_code_to_value(col['column_key'], code)
        
        accident_data['custom_data'] = json.dumps(custom_data, ensure_ascii=False)
    except:
        pass
    
    return accident_data

@app.route("/accident-register")
def accident_register():
    """ì‚¬ê³  ë“±ë¡ í˜ì´ì§€"""
    logging.info("ì‚¬ê³  ë“±ë¡ í˜ì´ì§€ ì ‘ê·¼")
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row  # Row ê°ì²´ë¡œ ë°˜í™˜
    
    # ë™ì  ì»¬ëŸ¼ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    dynamic_columns_rows = conn.execute("""
        SELECT * FROM accident_column_config 
        WHERE is_active = 1 
        ORDER BY column_order
    """).fetchall()
    
    # Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    dynamic_columns = [dict(row) for row in dynamic_columns_rows]
    
    conn.close()
    
    # ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼ì— ëŒ€í•´ ì½”ë“œ-ê°’ ë§¤í•‘ ì ìš©
    for col in dynamic_columns:
        if col['column_type'] == 'dropdown':
            # ì½”ë“œ-ê°’ ë§¤í•‘ ë°©ì‹ìœ¼ë¡œ ì˜µì…˜ ê°€ì ¸ì˜¤ê¸°
            code_options = get_dropdown_options_for_display(col['column_key'])
            if code_options:
                # ìƒˆë¡œìš´ ë°©ì‹ì˜ ì˜µì…˜ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                col['dropdown_options_mapped'] = code_options
                logging.info(f"  - {col['column_name']} ({col['column_key']}): ì½”ë“œ-ê°’ ë§¤í•‘ {len(code_options)}ê°œ ì˜µì…˜ = {code_options}")
            else:
                # ê¸°ì¡´ JSON ë°©ì‹ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
                col['dropdown_options_mapped'] = None
                logging.info(f"  - {col['column_name']} ({col['column_key']}): ê¸°ì¡´ JSON ë°©ì‹ ì‚¬ìš©, dropdown_options = {col.get('dropdown_options')}")
    
    logging.info(f"ë™ì  ì»¬ëŸ¼ {len(dynamic_columns)}ê°œ ë¡œë“œë¨")
    
    # íŒì—… ëª¨ë“œì¸ì§€ í™•ì¸
    is_popup = request.args.get('popup') == '1'
    
    return render_template('accident-register.html',
                         dynamic_columns=dynamic_columns,
                         menu=MENU_CONFIG,
                         is_popup=is_popup)

@app.route("/register-accident", methods=["POST"])
def register_accident():
    """ìƒˆ ì‚¬ê³  ë“±ë¡"""
    conn = None
    try:
        import json
        import datetime
        
        # ê¸°ë³¸ì •ë³´ í•„ë“œë“¤ ë°›ê¸°
        accident_name = request.form.get('accident_name', '')
        accident_date = request.form.get('accident_date', '')
        accident_time = request.form.get('accident_time', '')
        accident_grade = request.form.get('accident_grade', '')
        accident_type = request.form.get('accident_type', '')
        injury_type = request.form.get('injury_type', '')
        injury_form = request.form.get('injury_form', '')
        workplace = request.form.get('workplace', '')
        building = request.form.get('building', '')
        floor = request.form.get('floor', '')
        location_detail = request.form.get('location_detail', '')
        day_of_week = request.form.get('day_of_week', '')
        responsible_company1 = request.form.get('responsible_company1', '')
        responsible_company1_no = request.form.get('responsible_company1_no', '')
        responsible_company2 = request.form.get('responsible_company2', '')
        responsible_company2_no = request.form.get('responsible_company2_no', '')
        
        detailed_content = request.form.get('detailed_content')
        custom_data = json.loads(request.form.get('custom_data', '{}'))  # ë™ì  ì»¬ëŸ¼
        attachment_data = json.loads(request.form.get('attachment_data', '[]'))
        files = request.files.getlist('files')
        
        logging.info(f"ë“±ë¡ ìš”ì²­ ë°›ìŒ - ì‚¬ê³ ëª…: {accident_name}")
        logging.info(f"ì‚¬ê³  ë‚ ì§œ: {accident_date}, ì‹œê°„: {accident_time}")
        logging.info(f"ë™ì  ì»¬ëŸ¼ ë°ì´í„°: {custom_data}")
        logging.info(f"ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {len(files)}")
        
        # ìƒˆ ì‚¬ê³ ë²ˆí˜¸ ìƒì„± (ìˆ˜ê¸°ì…ë ¥: ACCYYMMDD00 í˜•ì‹)
        today = datetime.date.today()
        date_part = today.strftime('%y%m%d')  # YYMMDD í˜•ì‹
        accident_number_prefix = f"ACC{date_part}"
        
        conn = sqlite3.connect(DB_PATH, timeout=30.0)
        conn.execute("PRAGMA journal_mode=WAL")
        cursor = conn.cursor()
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ì‚¬ê³ ë²ˆí˜¸ ì°¾ê¸°
        cursor.execute("""
            SELECT accident_number FROM accidents_cache 
            WHERE accident_number LIKE ? 
            ORDER BY accident_number DESC 
            LIMIT 1
        """, (f"{accident_number_prefix}%",))
        
        last_accident = cursor.fetchone()
        if last_accident:
            # ë§ˆì§€ë§‰ ë²ˆí˜¸ì—ì„œ 1 ì¦ê°€ (ë’¤ 2ìë¦¬)
            last_num = int(last_accident[0][-2:])
            accident_number = f"{accident_number_prefix}{str(last_num + 1).zfill(2)}"
        else:
            accident_number = f"{accident_number_prefix}01"
        
        logging.info(f"ìƒˆ ì‚¬ê³  ë“±ë¡: {accident_number}")
        
        # 1. ê¸°ë³¸ ì‚¬ê³  ì •ë³´ ë“±ë¡ (ê¸°ë³¸ì •ë³´ + ë™ì  ì»¬ëŸ¼)
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì—†ëŠ” ê²½ìš° ì¶”ê°€
        cursor.execute("PRAGMA table_info(accidents_cache)")
        columns = [col[1] for col in cursor.fetchall()]
        
        # í•„ìˆ˜ ì»¬ëŸ¼ë“¤ ì²´í¬ ë° ì¶”ê°€
        required_columns = [
            ('accident_number', 'TEXT'),
            ('accident_name', 'TEXT'),
            ('accident_date', 'TEXT'),
            ('accident_time', 'TEXT'),
            ('accident_datetime', 'TEXT'),
            ('accident_grade', 'TEXT'),
            ('accident_type', 'TEXT'),
            ('injury_type', 'TEXT'),
            ('injury_form', 'TEXT'),
            ('workplace', 'TEXT'),
            ('building', 'TEXT'),
            ('floor', 'TEXT'),
            ('location_detail', 'TEXT'),
            ('day_of_week', 'TEXT'),
            ('responsible_company1', 'TEXT'),
            ('responsible_company1_no', 'TEXT'),
            ('responsible_company2', 'TEXT'),
            ('responsible_company2_no', 'TEXT'),
            ('custom_data', 'TEXT')
        ]
        
        for col_name, col_type in required_columns:
            if col_name not in columns:
                cursor.execute(f"ALTER TABLE accidents_cache ADD COLUMN {col_name} {col_type}")
                logging.info(f"ì»¬ëŸ¼ ì¶”ê°€: {col_name}")
        
        # datetime ì¡°í•© (ì •ë ¬ìš©)
        if accident_date and accident_time:
            accident_datetime = f"{accident_date} {accident_time}"
        elif accident_date:
            accident_datetime = f"{accident_date} 00:00"
        else:
            accident_datetime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
        
        cursor.execute("""
            INSERT INTO accidents_cache (
                accident_number, 
                accident_name,
                accident_date,
                accident_time,
                accident_datetime,
                accident_grade,
                accident_type,
                injury_type,
                injury_form,
                workplace,
                building,
                floor,
                location_detail,
                day_of_week,
                responsible_company1,
                responsible_company1_no,
                responsible_company2,
                responsible_company2_no,
                custom_data,
                business_number
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            accident_number,
            accident_name or f"ì‚¬ê³ _{accident_number}",
            accident_date or today.strftime('%Y-%m-%d'),
            accident_time or '',
            accident_datetime,
            accident_grade or '',
            accident_type or '',
            injury_type or '',
            injury_form or '',
            workplace or '',
            building or '',
            floor or '',
            location_detail or '',
            day_of_week or '',
            responsible_company1 or '',
            responsible_company1_no or '',
            responsible_company2 or '',
            responsible_company2_no or '',
            json.dumps(custom_data),
            responsible_company1_no or "DIRECT-ENTRY"  # ìˆ˜ê¸°ì…ë ¥ í‘œì‹œ
        ))
        
        # 2. ìƒì„¸ë‚´ìš© ì €ì¥
        if detailed_content:
            cursor.execute("""
                INSERT INTO accident_details (accident_number, detailed_content, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
            """, (accident_number, detailed_content))
        
        # 3. ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
        if files:
            upload_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'uploads', 'accidents')
            os.makedirs(upload_folder, exist_ok=True)
            
            for i, file in enumerate(files):
                if file and file.filename:
                    filename = secure_filename(file.filename)
                    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
                    unique_filename = f"{accident_number}_{timestamp}_{filename}"
                    file_path = os.path.join(upload_folder, unique_filename)
                    
                    file.save(file_path)
                    
                    # ì²¨ë¶€íŒŒì¼ ì •ë³´ ì €ì¥
                    description = attachment_data[i]['description'] if i < len(attachment_data) else ''
                    cursor.execute("""
                        INSERT INTO accident_attachments (accident_number, file_name, file_path, file_size, description)
                        VALUES (?, ?, ?, ?, ?)
                    """, (accident_number, filename, file_path, os.path.getsize(file_path), description))
        
        conn.commit()
        logging.info(f"ì‚¬ê³  {accident_number} ë“±ë¡ ì™„ë£Œ")
        
        return jsonify({"success": True, "accident_number": accident_number})
        
    except Exception as e:
        if conn:
            conn.rollback()
        logging.error(f"ì‚¬ê³  ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)})
    finally:
        if conn:
            conn.close()

@app.route("/verify-password", methods=["POST"])
def verify_password():
    """ê²Œì‹œíŒë³„ ë¹„ë°€ë²ˆí˜¸ ê²€ì¦"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "message": "No data received"}), 400
            
        password = data.get('password')
        board_type = data.get('board_type', 'default')  # partner, accident, ë˜ëŠ” default
        
        if not password:
            return jsonify({"success": False, "message": "Password not provided"}), 400
        
        # ê²Œì‹œíŒ íƒ€ì…ë³„ ë¹„ë°€ë²ˆí˜¸ í™•ì¸
        correct_password = None
        
        if board_type == 'partner':
            # í˜‘ë ¥ì‚¬ ê²Œì‹œíŒ ë¹„ë°€ë²ˆí˜¸
            correct_password = db_config.config.get('PASSWORDS', 'PARTNER_EDIT_PASSWORD', fallback=None)
        elif board_type == 'accident':
            # ì‚¬ê³  ê²Œì‹œíŒ ë¹„ë°€ë²ˆí˜¸
            correct_password = db_config.config.get('PASSWORDS', 'ACCIDENT_EDIT_PASSWORD', fallback=None)
        else:
            # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ (ê¸°ì¡´ í˜¸í™˜ì„±)
            correct_password = db_config.config.get('DEFAULT', 'EDIT_PASSWORD')
        
        # ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì‚¬ìš©
        if not correct_password:
            correct_password = db_config.config.get('DEFAULT', 'EDIT_PASSWORD')
        
        logging.info(f"ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ ìš”ì²­: board_type={board_type}")
        
        if password == correct_password:
            return jsonify({"success": True})
        else:
            return jsonify({"success": False, "message": "ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."})
    except Exception as e:
        logging.error(f"ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/update-partner", methods=["POST"])
def update_partner():
    """í˜‘ë ¥ì‚¬ ì •ë³´ ì—…ë°ì´íŠ¸"""
    conn = None
    try:
        import json
        
        business_number = request.form.get('business_number')
        detailed_content = request.form.get('detailed_content')
        deleted_attachments = json.loads(request.form.get('deleted_attachments', '[]'))
        attachment_data = json.loads(request.form.get('attachment_data', '[]'))
        files = request.files.getlist('files')
        
        print(f"Business Number: {business_number}")
        print(f"Files count: {len(files)}")
        print(f"Attachment data: {attachment_data}")
        
        # í˜‘ë ¥ì‚¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ë¨¼ì € í™•ì¸)
        partner = partner_manager.get_partner_by_business_number(business_number)
        if not partner:
            from flask import jsonify
            return jsonify({"success": False, "message": "í˜‘ë ¥ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})
        
        print(f"Connecting to database: {DB_PATH}")
        conn = sqlite3.connect(DB_PATH, timeout=30.0)  # timeout ì¶”ê°€
        conn.execute("PRAGMA journal_mode=WAL")  # WAL ëª¨ë“œë¡œ ë³€ê²½ (ë™ì‹œì„± ê°œì„ )
        cursor = conn.cursor()
        
        logging.info(f"ì—…ë°ì´íŠ¸ ëŒ€ìƒ í˜‘ë ¥ì‚¬: {business_number}")
        
        # 1. í˜‘ë ¥ì‚¬ ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸ (partner_details í…Œì´ë¸”)
        logging.info(f"ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸: {detailed_content[:50]}...")
        cursor.execute("""
            INSERT OR REPLACE INTO partner_details (business_number, detailed_content, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        """, (business_number, detailed_content))
        logging.info("ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # 2. ì‚­ì œëœ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
        for attachment_id in deleted_attachments:
            cursor.execute("DELETE FROM partner_attachments WHERE id = ?", (attachment_id,))
        
        # 3. ê¸°ì¡´ ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
        for attachment in attachment_data:
            if attachment['id'] and not attachment.get('isNew'):
                cursor.execute("""
                    UPDATE partner_attachments 
                    SET description = ? 
                    WHERE id = ?
                """, (attachment['description'], attachment['id']))
        
        # 4. ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
        import os
        upload_folder = os.path.join(os.getcwd(), 'uploads')
        if not os.path.exists(upload_folder):
            os.makedirs(upload_folder)
            
        # ìƒˆ íŒŒì¼ë“¤ê³¼ ìƒˆ ì²¨ë¶€íŒŒì¼ ë°ì´í„° ë§¤ì¹­
        new_attachments = [a for a in attachment_data if a.get('isNew')]
        print(f"New attachments: {new_attachments}")
        
        for i, file in enumerate(files):
            if file.filename and i < len(new_attachments):
                filename = file.filename
                # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                import time
                timestamp = str(int(time.time()))
                name, ext = os.path.splitext(filename)
                unique_filename = f"{name}_{timestamp}{ext}"
                file_path = os.path.join(upload_folder, unique_filename)
                
                print(f"Saving file: {filename} as {unique_filename}")
                file.save(file_path)
                
                attachment_info = new_attachments[i]
                cursor.execute("""
                    INSERT INTO partner_attachments 
                    (business_number, file_name, file_path, file_size, description)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    business_number,
                    filename,  # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                    file_path,
                    os.path.getsize(file_path),
                    attachment_info['description']
                ))
                logging.info(f"ì²¨ë¶€íŒŒì¼ ì¶”ê°€: {filename} - {attachment_info['description']}")
        
        # ì»¤ë°‹ ì „ í™•ì¸
        check_result = cursor.execute("SELECT COUNT(*) FROM partner_attachments WHERE business_number = ?", (business_number,)).fetchone()
        logging.info(f"ì»¤ë°‹ ì „ {business_number} í˜‘ë ¥ì‚¬ ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {check_result[0]}ê°œ")
        
        try:
            conn.commit()
            logging.info("ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë°‹ ì„±ê³µ")
            
            # ì»¤ë°‹ í›„ ë‹¤ì‹œ í™•ì¸
            check_result2 = cursor.execute("SELECT COUNT(*) FROM partner_attachments WHERE business_number = ?", (business_number,)).fetchone()
            logging.info(f"ì»¤ë°‹ í›„ {business_number} í˜‘ë ¥ì‚¬ ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {check_result2[0]}ê°œ")
            
            conn.close()
            
            # ìƒˆë¡œìš´ ì—°ê²°ë¡œ ë‹¤ì‹œ í™•ì¸
            logging.info("ìƒˆ ì—°ê²°ë¡œ ë°ì´í„° ì§€ì†ì„± í™•ì¸...")
            verify_conn = sqlite3.connect(DB_PATH)
            verify_result = verify_conn.execute("SELECT COUNT(*) FROM partner_attachments WHERE business_number = ?", (business_number,)).fetchone()
            logging.info(f"ìƒˆ ì—°ê²° í™•ì¸: {business_number} í˜‘ë ¥ì‚¬ ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {verify_result[0]}ê°œ")
            verify_conn.close()
            
            from flask import jsonify
            return jsonify({"success": True})
        except Exception as commit_error:
            print(f"Commit failed: {commit_error}")
            conn.rollback()
            conn.close()
            from flask import jsonify
            return jsonify({"success": False, "message": f"Commit failed: {str(commit_error)}"})
        
    except Exception as e:
        if conn:
            try:
                conn.rollback()
                conn.close()
            except:
                pass
        from flask import jsonify
        logging.error(f"ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/update-accident", methods=["POST"])
def update_accident():
    """ì‚¬ê³  ì •ë³´ ì—…ë°ì´íŠ¸"""
    conn = None
    try:
        import json
        
        accident_number = request.form.get('accident_number')
        detailed_content = request.form.get('detailed_content')
        custom_data = request.form.get('custom_data', '{}')  # Phase 2: ë™ì  ì»¬ëŸ¼ ë°ì´í„°
        deleted_attachments = json.loads(request.form.get('deleted_attachments', '[]'))
        attachment_data = json.loads(request.form.get('attachment_data', '[]'))
        files = request.files.getlist('files')
        
        print(f"Accident Number: {accident_number}")
        print(f"Custom Data received: {custom_data}")  # ë””ë²„ê¹…ìš© ì¶”ê°€
        print(f"Files count: {len(files)}")
        print(f"Attachment data: {attachment_data}")
        
        # ì‚¬ê³ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„± (ìˆ˜ê¸°ì…ë ¥ìš©)
        if not accident_number:
            accident_number = generate_manual_accident_number(cursor)
            logging.info(f"ìë™ ìƒì„±ëœ ì‚¬ê³ ë²ˆí˜¸: {accident_number}")
        
        # ì‚¬ê³  í˜•ì‹ ê²€ì¦ (Kë¡œ ì‹œì‘í•˜ëŠ” ì™¸ë¶€ì‹œìŠ¤í…œ ì‚¬ê³  ë˜ëŠ” ACCë¡œ ì‹œì‘í•˜ëŠ” ìˆ˜ê¸°ì…ë ¥ ì‚¬ê³ )
        if not (accident_number.startswith('K') or accident_number.startswith('ACC')):
            from flask import jsonify
            return jsonify({"success": False, "message": "ì˜ëª»ëœ ì‚¬ê³ ë²ˆí˜¸ í˜•ì‹ì…ë‹ˆë‹¤."})
        
        print(f"Connecting to database: {DB_PATH}")
        conn = sqlite3.connect(DB_PATH, timeout=30.0)  # timeout ì¶”ê°€
        conn.execute("PRAGMA journal_mode=WAL")  # WAL ëª¨ë“œë¡œ ë³€ê²½ (ë™ì‹œì„± ê°œì„ )
        cursor = conn.cursor()
        
        logging.info(f"ì—…ë°ì´íŠ¸ ëŒ€ìƒ ì‚¬ê³ : {accident_number}")
        
        # 1. ì‚¬ê³  ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸ (í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±)
        logging.info(f"ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸: {detailed_content[:50]}...")
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS accident_details (
                accident_number TEXT PRIMARY KEY,
                detailed_content TEXT,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cursor.execute("""
            INSERT OR REPLACE INTO accident_details (accident_number, detailed_content, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        """, (accident_number, detailed_content))
        logging.info("ìƒì„¸ë‚´ìš© ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # Phase 2: ë™ì  ì»¬ëŸ¼ ë°ì´í„° ì €ì¥ (accidents_cache í…Œì´ë¸”ì— custom_data ì—…ë°ì´íŠ¸)
        # accidents_cache í…Œì´ë¸”ì— accident_number ì»¬ëŸ¼ ì¶”ê°€ (ì—†ìœ¼ë©´)
        cursor.execute("""
            PRAGMA table_info(accidents_cache)
        """)
        columns = [col[1] for col in cursor.fetchall()]
        
        if 'accident_number' not in columns:
            cursor.execute("""
                ALTER TABLE accidents_cache ADD COLUMN accident_number TEXT
            """)
            logging.info("accident_number ì»¬ëŸ¼ ì¶”ê°€ë¨")
        
        if 'accident_name' not in columns:
            cursor.execute("""
                ALTER TABLE accidents_cache ADD COLUMN accident_name TEXT
            """)
            logging.info("accident_name ì»¬ëŸ¼ ì¶”ê°€ë¨")
        
        # ë¨¼ì € í•´ë‹¹ ì‚¬ê³ ê°€ accidents_cacheì— ìˆëŠ”ì§€ í™•ì¸
        cursor.execute("SELECT id FROM accidents_cache WHERE accident_number = ?", (accident_number,))
        accident_row = cursor.fetchone()
        
        if accident_row:
            # ê¸°ì¡´ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
            cursor.execute("""
                UPDATE accidents_cache 
                SET custom_data = ?
                WHERE accident_number = ?
            """, (custom_data, accident_number))
            logging.info(f"ë™ì  ì»¬ëŸ¼ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {accident_number}")
        else:
            # ìƒˆ ë ˆì½”ë“œ ìƒì„± (ì—…ì²´ ì •ë³´ëŠ” ì„ íƒì )
            # ë¹„ê³µì‹/ì§ì ‘ë“±ë¡ ì‚¬ê³ ëŠ” 'DIRECT-ENTRY'ë¡œ í‘œì‹œ
            cursor.execute("""
                INSERT INTO accidents_cache (business_number, accident_number, accident_name, custom_data, accident_date)
                VALUES (?, ?, ?, ?, date('now'))
            """, ('DIRECT-ENTRY', accident_number, f"ì‚¬ê³ _{accident_number}", custom_data))
            logging.info(f"ìƒˆ ì‚¬ê³  ë ˆì½”ë“œ ìƒì„± (ì§ì ‘ë“±ë¡) ë° ë™ì  ì»¬ëŸ¼ ë°ì´í„° ì €ì¥: {accident_number}")
        
        # 2. ì‚¬ê³  ì²¨ë¶€íŒŒì¼ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS accident_attachments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                accident_number TEXT,
                file_name TEXT NOT NULL,
                file_path TEXT NOT NULL,
                file_size INTEGER,
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 3. ì‚­ì œëœ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
        for attachment_id in deleted_attachments:
            cursor.execute("DELETE FROM accident_attachments WHERE id = ?", (attachment_id,))
        
        # 4. ê¸°ì¡´ ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
        for attachment in attachment_data:
            if attachment['id'] and not attachment.get('isNew'):
                cursor.execute("""
                    UPDATE accident_attachments 
                    SET description = ? 
                    WHERE id = ?
                """, (attachment['description'], attachment['id']))
        
        # 5. ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
        import os
        upload_folder = os.path.join(os.getcwd(), 'uploads')
        if not os.path.exists(upload_folder):
            os.makedirs(upload_folder)
            
        # ìƒˆ íŒŒì¼ë“¤ê³¼ ìƒˆ ì²¨ë¶€íŒŒì¼ ë°ì´í„° ë§¤ì¹­
        new_attachments = [a for a in attachment_data if a.get('isNew')]
        print(f"New attachments: {new_attachments}")
        
        for i, file in enumerate(files):
            if file.filename and i < len(new_attachments):
                filename = file.filename
                # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                import time
                timestamp = str(int(time.time()))
                name, ext = os.path.splitext(filename)
                unique_filename = f"{name}_{timestamp}{ext}"
                file_path = os.path.join(upload_folder, unique_filename)
                
                print(f"Saving file: {filename} as {unique_filename}")
                file.save(file_path)
                
                attachment_info = new_attachments[i]
                cursor.execute("""
                    INSERT INTO accident_attachments 
                    (accident_number, file_name, file_path, file_size, description)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    accident_number,
                    filename,  # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                    file_path,
                    os.path.getsize(file_path),
                    attachment_info['description']
                ))
                logging.info(f"ì²¨ë¶€íŒŒì¼ ì¶”ê°€: {filename} - {attachment_info['description']}")
        
        # ì»¤ë°‹ ì „ í™•ì¸
        check_result = cursor.execute("SELECT COUNT(*) FROM accident_attachments WHERE accident_number = ?", (accident_number,)).fetchone()
        logging.info(f"ì»¤ë°‹ ì „ {accident_number} ì‚¬ê³  ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {check_result[0]}ê°œ")
        
        try:
            conn.commit()
            logging.info("ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë°‹ ì„±ê³µ")
            
            # ì»¤ë°‹ í›„ ë‹¤ì‹œ í™•ì¸
            check_result2 = cursor.execute("SELECT COUNT(*) FROM accident_attachments WHERE accident_number = ?", (accident_number,)).fetchone()
            logging.info(f"ì»¤ë°‹ í›„ {accident_number} ì‚¬ê³  ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {check_result2[0]}ê°œ")
            
            conn.close()
            
            # ìƒˆë¡œìš´ ì—°ê²°ë¡œ ë‹¤ì‹œ í™•ì¸
            logging.info("ìƒˆ ì—°ê²°ë¡œ ë°ì´í„° ì§€ì†ì„± í™•ì¸...")
            verify_conn = sqlite3.connect(DB_PATH)
            verify_result = verify_conn.execute("SELECT COUNT(*) FROM accident_attachments WHERE accident_number = ?", (accident_number,)).fetchone()
            logging.info(f"ìƒˆ ì—°ê²° í™•ì¸: {accident_number} ì‚¬ê³  ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {verify_result[0]}ê°œ")
            verify_conn.close()
            
            from flask import jsonify
            return jsonify({"success": True})
        except Exception as commit_error:
            print(f"Commit failed: {commit_error}")
            conn.rollback()
            conn.close()
            from flask import jsonify
            return jsonify({"success": False, "message": f"Commit failed: {str(commit_error)}"})
        
    except Exception as e:
        if conn:
            try:
                conn.rollback()
                conn.close()
            except:
                pass
        from flask import jsonify
        logging.error(f"ì‚¬ê³  ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/download/<int:attachment_id>")
def download_attachment(attachment_id):
    """ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ (í˜‘ë ¥ì‚¬ ë° ì‚¬ê³  í†µí•©)"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    
    # ë¨¼ì € partner_attachmentsì—ì„œ ì°¾ê¸°
    attachment = conn.execute(
        "SELECT * FROM partner_attachments WHERE id = ?", 
        (attachment_id,)
    ).fetchone()
    
    # partner_attachmentsì— ì—†ìœ¼ë©´ accident_attachmentsì—ì„œ ì°¾ê¸°
    if not attachment:
        attachment = conn.execute(
            "SELECT * FROM accident_attachments WHERE id = ?", 
            (attachment_id,)
        ).fetchone()
    
    conn.close()
    
    if not attachment:
        return "File not found", 404
    
    from flask import send_file
    import os
    
    # DBì— ì €ì¥ëœ file_path ì‚¬ìš© (ì‹¤ì œ ì €ì¥ëœ ê²½ë¡œ)
    stored_file_path = attachment['file_path']
    
    # ì ˆëŒ€ ê²½ë¡œì¸ì§€ ìƒëŒ€ ê²½ë¡œì¸ì§€ í™•ì¸
    if os.path.isabs(stored_file_path):
        actual_file_path = stored_file_path
    else:
        # ìƒëŒ€ ê²½ë¡œë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„±
        actual_file_path = os.path.join(os.getcwd(), stored_file_path.lstrip('/\\'))
    
    logging.info(f"ë‹¤ìš´ë¡œë“œ ìš”ì²­: ID={attachment_id}, íŒŒì¼={attachment['file_name']}, ê²½ë¡œ={actual_file_path}")
    
    try:
        if os.path.exists(actual_file_path):
            return send_file(
                actual_file_path,
                as_attachment=True,
                download_name=attachment['file_name']
            )
        else:
            logging.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {actual_file_path}")
            return "File not found on disk", 404
    except Exception as e:
        logging.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return f"Download error: {str(e)}", 500

@app.route("/partner-attachments/<business_number>")
def get_partner_attachments(business_number):
    """í˜‘ë ¥ì‚¬ ì²¨ë¶€íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    attachments = conn.execute("""
        SELECT * FROM partner_attachments 
        WHERE business_number = ? 
        ORDER BY upload_date DESC
    """, (business_number,)).fetchall()
    conn.close()
    
    from flask import jsonify
    return jsonify([dict(attachment) for attachment in attachments])

# ===== Phase 1: ë™ì  ì»¬ëŸ¼ ê´€ë¦¬ API =====

@app.route("/api/accident-columns", methods=["GET"])
def get_accident_columns():
    """ì‚¬ê³  í˜ì´ì§€ ë™ì  ì»¬ëŸ¼ ì„¤ì • ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        columns = conn.execute("""
            SELECT * FROM accident_column_config 
            ORDER BY column_order
        """).fetchall()
        conn.close()
        
        # ê´€ë¦¬ í˜ì´ì§€ì—ì„œëŠ” ëª¨ë“  ì»¬ëŸ¼ ë°˜í™˜ (í™œì„±/ë¹„í™œì„± ëª¨ë‘)
        return jsonify([dict(col) for col in columns])
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

# ê´€ë¦¬ì ì¸ì¦ ë¼ìš°íŠ¸
@app.route("/admin/login", methods=["POST"])
def admin_login():
    """ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ ì¸ì¦ ì²˜ë¦¬"""
    password = request.form.get('password')
    redirect_url = request.form.get('redirect_url', '/admin/menu-settings')
    
    if password == ADMIN_PASSWORD:
        session['admin_authenticated'] = True
        return redirect(redirect_url)
    else:
        return render_template('admin-login.html', 
                             error='ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.',
                             redirect_url=redirect_url,
                             menu=MENU_CONFIG)

@app.route("/admin/logout")
def admin_logout():
    """ê´€ë¦¬ì ë¡œê·¸ì•„ì›ƒ"""
    session.pop('admin_authenticated', None)
    return redirect(url_for('index'))

# ì´ ë¼ìš°íŠ¸ëŠ” ì•„ë˜ì— ë” ì™„ì „í•œ ë²„ì „ì´ ìˆìœ¼ë¯€ë¡œ ì œê±°ë¨

@app.route("/admin/accident-columns")
@require_admin_auth
def admin_accident_columns():
    """ì‚¬ê³  ì»¬ëŸ¼ ê´€ë¦¬ í˜ì´ì§€"""
    return render_template('admin-accident-columns.html', menu=MENU_CONFIG)

@app.route("/admin/accident-columns-v2")
@require_admin_auth
def admin_accident_columns_v2():
    """ì‚¬ê³  ì»¬ëŸ¼ ê´€ë¦¬ í˜ì´ì§€ V2 - ì½”ë“œ ë§¤í•‘ ë°©ì‹"""
    return render_template('admin-accident-columns-v2.html', menu=MENU_CONFIG)

@app.route("/admin/accident-columns-v3")
@require_admin_auth
def admin_accident_columns_v3():
    """ì‚¬ê³  ì»¬ëŸ¼ ê´€ë¦¬ í˜ì´ì§€ V3 - ì™„ì „í•œ ì½”ë“œ ë§¤í•‘ ì‹œìŠ¤í…œ"""
    return render_template('admin-accident-columns-v3.html', menu=MENU_CONFIG)

@app.route("/admin/accident-columns-enhanced")
@require_admin_auth
def admin_accident_columns_enhanced():
    """ì‚¬ê³  ì»¬ëŸ¼ ê´€ë¦¬ í˜ì´ì§€ Enhanced - Phase 2 ê³ ê¸‰ ê¸°ëŠ¥"""
    return render_template('admin-accident-columns-enhanced.html', menu=MENU_CONFIG)

@app.route("/admin/accident-columns-simplified")
@require_admin_auth
def admin_accident_columns_simplified():
    """ì‚¬ê³  ì»¬ëŸ¼ ê´€ë¦¬ í˜ì´ì§€ Simplified - ê°„ì†Œí™” ë²„ì „"""
    return render_template('admin-accident-columns-simplified.html', menu=MENU_CONFIG)

@app.route("/admin/menu-settings")
@require_admin_auth
def admin_menu_settings():
    """ë©”ë‰´ ì„¤ì • í˜ì´ì§€"""
    return render_template('admin-menu-settings.html', menu=MENU_CONFIG)

@app.route("/admin/permission-settings")
@require_admin_auth
def admin_permission_settings():
    """ê¶Œí•œ ì„¤ì • í˜ì´ì§€"""
    return render_template('admin-permission-settings.html', menu=MENU_CONFIG)

@app.route("/admin/data-management")
@require_admin_auth
def admin_data_management():
    """ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€"""
    return render_template('admin-data-management.html', menu=MENU_CONFIG)

@app.route("/api/accidents/deleted")
def get_deleted_accidents():
    """ì‚­ì œëœ ì‚¬ê³  ëª©ë¡ API"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    
    # ì‚­ì œëœ ì‚¬ê³ ë§Œ ì¡°íšŒ
    deleted_accidents_rows = conn.execute("""
        SELECT * FROM accidents_cache 
        WHERE is_deleted = 1
        ORDER BY accident_date DESC, accident_number DESC
    """).fetchall()
    
    deleted_accidents = [dict(row) for row in deleted_accidents_rows]
    conn.close()
    
    return jsonify({"success": True, "accidents": deleted_accidents})

@app.route("/api/partners/deleted")
def get_deleted_partners():
    """ì‚­ì œëœ í˜‘ë ¥ì‚¬ ëª©ë¡ API"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    
    # ì‚­ì œëœ í˜‘ë ¥ì‚¬ë§Œ ì¡°íšŒ
    deleted_partners_rows = conn.execute("""
        SELECT * FROM partners_cache 
        WHERE is_deleted = 1
        ORDER BY company_name
    """).fetchall()
    
    deleted_partners = [dict(row) for row in deleted_partners_rows]
    conn.close()
    
    return jsonify({"success": True, "partners": deleted_partners})

@app.route('/api/accidents/delete', methods=['POST'])
def delete_accidents():
    """ì„ íƒí•œ ì‚¬ê³ ë“¤ì„ ì†Œí”„íŠ¸ ì‚­ì œ"""
    try:
        data = request.json
        ids = data.get('ids', [])
        
        if not ids:
            return jsonify({"success": False, "message": "ì‚­ì œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        # ëª¨ë“  ì‚¬ê³  ì‚­ì œ ê°€ëŠ¥ (ACC, K ëª¨ë‘)
        placeholders = ','.join('?' * len(ids))
        cursor.execute(f"""
            UPDATE accidents_cache 
            SET is_deleted = 1 
            WHERE id IN ({placeholders})
        """, ids)
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "deleted_count": deleted_count,
            "message": f"{deleted_count}ê±´ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        logging.error(f"ì‚¬ê³  ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/api/accidents/restore', methods=['POST'])
def restore_accidents():
    """ì‚­ì œëœ ì‚¬ê³ ë“¤ì„ ë³µêµ¬"""
    try:
        data = request.json
        ids = data.get('ids', [])
        
        if not ids:
            return jsonify({"success": False, "message": "ë³µêµ¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        # ì„ íƒí•œ ì‚¬ê³ ë“¤ì„ ë³µêµ¬ (is_deleted = 0)
        placeholders = ','.join('?' * len(ids))
        cursor.execute(f"""
            UPDATE accidents_cache 
            SET is_deleted = 0 
            WHERE id IN ({placeholders})
        """, ids)
        
        restored_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "restored_count": restored_count,
            "message": f"{restored_count}ê±´ì´ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        logging.error(f"ì‚¬ê³  ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/api/partners/restore', methods=['POST'])
def restore_partners():
    """ì‚­ì œëœ í˜‘ë ¥ì‚¬ë“¤ì„ ë³µêµ¬"""
    try:
        data = request.json
        business_numbers = data.get('business_numbers', [])
        
        if not business_numbers:
            return jsonify({"success": False, "message": "ë³µêµ¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        # ì„ íƒí•œ í˜‘ë ¥ì‚¬ë“¤ì„ ë³µêµ¬ (is_deleted = 0)
        placeholders = ','.join('?' * len(business_numbers))
        cursor.execute(f"""
            UPDATE partners_cache 
            SET is_deleted = 0 
            WHERE business_number IN ({placeholders})
        """, business_numbers)
        
        restored_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "restored_count": restored_count,
            "message": f"{restored_count}ê°œì˜ í˜‘ë ¥ì‚¬ê°€ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        logging.error(f"í˜‘ë ¥ì‚¬ ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route('/api/buildings/search', methods=['GET'])
def search_buildings():
    """ê±´ë¬¼ ê²€ìƒ‰ API"""
    try:
        search_term = request.args.get('q', '').strip()
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        if search_term:
            cursor.execute("""
                SELECT building_code, building_name
                FROM building_master
                WHERE building_name LIKE ? OR building_code LIKE ?
                ORDER BY building_name
                LIMIT 50
            """, (f'%{search_term}%', f'%{search_term}%'))
        else:
            cursor.execute("""
                SELECT building_code, building_name
                FROM building_master
                ORDER BY building_name
                LIMIT 50
            """)
        
        buildings = []
        for row in cursor.fetchall():
            buildings.append({
                'building_code': row[0],
                'building_name': row[1]
            })
        
        conn.close()
        return jsonify({'success': True, 'buildings': buildings})
    except Exception as e:
        logging.error(f"ê±´ë¬¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/departments/search', methods=['GET'])
def search_departments():
    """ë¶€ì„œ ê²€ìƒ‰ API"""
    try:
        search_term = request.args.get('q', '').strip()
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        if search_term:
            cursor.execute("""
                SELECT d.dept_code, d.dept_name, 
                       p.dept_name as parent_name, d.dept_level
                FROM department_master d
                LEFT JOIN department_master p ON d.parent_dept_code = p.dept_code
                WHERE d.dept_name LIKE ? OR d.dept_code LIKE ?
                ORDER BY d.dept_level, d.dept_name
                LIMIT 50
            """, (f'%{search_term}%', f'%{search_term}%'))
        else:
            cursor.execute("""
                SELECT d.dept_code, d.dept_name, 
                       p.dept_name as parent_name, d.dept_level
                FROM department_master d
                LEFT JOIN department_master p ON d.parent_dept_code = p.dept_code
                ORDER BY d.dept_level, d.dept_name
                LIMIT 50
            """)
        
        departments = []
        for row in cursor.fetchall():
            departments.append({
                'dept_code': row[0],
                'dept_name': row[1],
                'parent_name': row[2] or '',
                'dept_level': row[3] or 0
            })
        
        conn.close()
        return jsonify({'success': True, 'departments': departments})
    except Exception as e:
        logging.error(f"ë¶€ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/search', methods=['GET'])
def api_search():
    """ë²”ìš© ê²€ìƒ‰ API"""
    try:
        search_type = request.args.get('type', 'person')
        search_value = request.args.get('value', 'person')
        search_term = request.args.get('q', '').strip()
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        results = []
        
        if search_type == 'person':
            # ë‹´ë‹¹ì ê²€ìƒ‰ (ë”ë¯¸ ë°ì´í„°)
            sample_persons = [
                {'employee_id': '10001', 'name': 'ê¹€ì² ìˆ˜', 'department': 'ì•ˆì „ë³´ê±´íŒ€'},
                {'employee_id': '10002', 'name': 'ì´ì˜í¬', 'department': 'ìƒì‚°1íŒ€'},
                {'employee_id': '10003', 'name': 'ë°•ë¯¼ìˆ˜', 'department': 'í’ˆì§ˆê´€ë¦¬íŒ€'},
                {'employee_id': '10004', 'name': 'ì •ìˆ˜ì§„', 'department': 'ì¸ì‚¬íŒ€'},
                {'employee_id': '10005', 'name': 'ìµœë™ìš±', 'department': 'ì´ë¬´íŒ€'}
            ]
            
            if search_term:
                if search_value == 'employee_id':
                    results = [p for p in sample_persons if search_term in p['employee_id']]
                else:
                    results = [p for p in sample_persons if search_term in p['name'] or search_term in p['department']]
            else:
                results = sample_persons
                
        elif search_type == 'company':
            # í˜‘ë ¥ì‚¬ ê²€ìƒ‰
            if search_term:
                if search_value == 'business_number':
                    cursor.execute("""
                        SELECT business_number, company_name, representative, 
                               business_type_major, NULL as phone
                        FROM partners_cache
                        WHERE business_number LIKE ? AND is_deleted = 0
                        LIMIT 50
                    """, (f'%{search_term}%',))
                else:
                    cursor.execute("""
                        SELECT business_number, company_name, representative, 
                               business_type_major, NULL as phone
                        FROM partners_cache
                        WHERE company_name LIKE ? AND is_deleted = 0
                        LIMIT 50
                    """, (f'%{search_term}%',))
            else:
                cursor.execute("""
                    SELECT business_number, company_name, representative, 
                           business_type_major, NULL as phone
                    FROM partners_cache
                    WHERE is_deleted = 0
                    LIMIT 50
                """)
            
            for row in cursor.fetchall():
                results.append({
                    'company_business_number': row[0],
                    'company_name': row[1],
                    'representative_name': row[2] or '',
                    'business_type': row[3] or '',
                    'company_phone': row[4] or ''
                })
                
        elif search_type == 'building':
            # ê±´ë¬¼ ê²€ìƒ‰ - ì™¸ë¶€ DBì—ì„œ ì¡°íšŒ
            try:
                from database_config import execute_SQL
                
                # config.iniì—ì„œ BUILDING_QUERY ê°€ì ¸ì˜¤ê¸°
                building_query = db_config.config.get('MASTER_DATA_QUERIES', 'BUILDING_QUERY')
                
                # ê²€ìƒ‰ì–´ ì¡°ê±´ ì¶”ê°€
                if search_term:
                    if search_value == 'building_code':
                        building_query += f" AND building_code LIKE '%{search_term}%'"
                    else:
                        building_query += f" AND building_name LIKE '%{search_term}%'"
                
                building_query += " ORDER BY building_name LIMIT 50"
                
                # ì™¸ë¶€ DBì—ì„œ ì‹¤í–‰
                df = execute_SQL(building_query)
                
                for _, row in df.iterrows():
                    results.append({
                        'building_code': row.get('building_code', ''),
                        'building_name': row.get('building_name', '')
                    })
                    
            except Exception as e:
                logging.warning(f"ì™¸ë¶€ DB ê±´ë¬¼ ì¡°íšŒ ì‹¤íŒ¨, ë¡œì»¬ DB ì‚¬ìš©: {e}")
                # ì™¸ë¶€ DB ì‹¤íŒ¨ ì‹œ ë¡œì»¬ DB ì‚¬ìš©
                if search_term:
                    if search_value == 'building_code':
                        cursor.execute("""
                            SELECT building_code, building_name
                            FROM building_master
                            WHERE building_code LIKE ?
                            ORDER BY building_name
                            LIMIT 50
                        """, (f'%{search_term}%',))
                    else:
                        cursor.execute("""
                            SELECT building_code, building_name
                            FROM building_master
                            WHERE building_name LIKE ?
                            ORDER BY building_name
                            LIMIT 50
                        """, (f'%{search_term}%',))
                else:
                    cursor.execute("""
                        SELECT building_code, building_name
                        FROM building_master
                        ORDER BY building_name
                        LIMIT 50
                    """)
                
                for row in cursor.fetchall():
                    results.append({
                        'building_code': row[0],
                        'building_name': row[1]
                    })
                
        elif search_type == 'department':
            # ë¶€ì„œ ê²€ìƒ‰ - ì™¸ë¶€ DBì—ì„œ ì¡°íšŒ
            try:
                from database_config import execute_SQL
                
                # config.iniì—ì„œ DEPARTMENT_QUERY ê°€ì ¸ì˜¤ê¸°
                department_query = db_config.config.get('MASTER_DATA_QUERIES', 'DEPARTMENT_QUERY')
                
                # ê²€ìƒ‰ì–´ ì¡°ê±´ ì¶”ê°€
                if search_term:
                    if search_value == 'dept_code':
                        department_query += f" AND dept_code LIKE '%{search_term}%'"
                    else:
                        department_query += f" AND dept_name LIKE '%{search_term}%'"
                
                department_query += " ORDER BY dept_level, dept_name LIMIT 50"
                
                # ì™¸ë¶€ DBì—ì„œ ì‹¤í–‰
                df = execute_SQL(department_query)
                
                for _, row in df.iterrows():
                    results.append({
                        'dept_code': row.get('dept_code', ''),
                        'dept_name': row.get('dept_name', ''),
                        'parent_name': row.get('parent_dept_code', ''),  # ë¶€ëª¨ ë¶€ì„œì½”ë“œë¥¼ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
                        'dept_level': row.get('dept_level', 0)
                    })
                    
            except Exception as e:
                logging.warning(f"ì™¸ë¶€ DB ë¶€ì„œ ì¡°íšŒ ì‹¤íŒ¨, ë¡œì»¬ DB ì‚¬ìš©: {e}")
                # ì™¸ë¶€ DB ì‹¤íŒ¨ ì‹œ ë¡œì»¬ DB ì‚¬ìš©
                if search_term:
                    if search_value == 'dept_code':
                        cursor.execute("""
                            SELECT d.dept_code, d.dept_name, 
                                   p.dept_name as parent_name, d.dept_level
                            FROM department_master d
                            LEFT JOIN department_master p ON d.parent_dept_code = p.dept_code
                            WHERE d.dept_code LIKE ?
                            ORDER BY d.dept_level, d.dept_name
                            LIMIT 50
                        """, (f'%{search_term}%',))
                    else:
                        cursor.execute("""
                            SELECT d.dept_code, d.dept_name, 
                                   p.dept_name as parent_name, d.dept_level
                            FROM department_master d
                            LEFT JOIN department_master p ON d.parent_dept_code = p.dept_code
                            WHERE d.dept_name LIKE ?
                            ORDER BY d.dept_level, d.dept_name
                            LIMIT 50
                        """, (f'%{search_term}%',))
                else:
                    cursor.execute("""
                        SELECT d.dept_code, d.dept_name, 
                               p.dept_name as parent_name, d.dept_level
                        FROM department_master d
                        LEFT JOIN department_master p ON d.parent_dept_code = p.dept_code
                        ORDER BY d.dept_level, d.dept_name
                        LIMIT 50
                    """)
                
                for row in cursor.fetchall():
                    results.append({
                        'dept_code': row[0],
                        'dept_name': row[1],
                        'parent_name': row[2] or '',
                        'dept_level': row[3] or 0
                    })
                
        elif search_type == 'contractor':
            # í˜‘ë ¥ì‚¬ ê·¼ë¡œì ê²€ìƒ‰ - ì™¸ë¶€ DBì—ì„œ ì¡°íšŒ
            try:
                from database_config import execute_SQL
                
                # config.iniì—ì„œ CONTRACTOR_QUERY ê°€ì ¸ì˜¤ê¸°
                contractor_query = db_config.config.get('MASTER_DATA_QUERIES', 'CONTRACTOR_QUERY')
                
                # ê²€ìƒ‰ì–´ ì¡°ê±´ ì¶”ê°€
                if search_term:
                    if search_value == 'worker_id':
                        contractor_query += f" AND worker_id LIKE '%{search_term}%'"
                    else:
                        contractor_query += f" AND worker_name LIKE '%{search_term}%'"
                
                contractor_query += " ORDER BY worker_name LIMIT 50"
                
                # ì™¸ë¶€ DBì—ì„œ ì‹¤í–‰
                df = execute_SQL(contractor_query)
                
                for _, row in df.iterrows():
                    results.append({
                        'worker_id': row.get('worker_id', ''),
                        'worker_name': row.get('worker_name', ''),
                        'company_name': row.get('company_name', ''),
                        'business_number': row.get('business_number', '')
                    })
                    
            except Exception as e:
                logging.warning(f"ì™¸ë¶€ DB í˜‘ë ¥ì‚¬ ê·¼ë¡œì ì¡°íšŒ ì‹¤íŒ¨, ë”ë¯¸ ë°ì´í„° ì‚¬ìš©: {e}")
                # ì™¸ë¶€ DB ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                sample_contractors = [
                    {'worker_id': 'C001', 'worker_name': 'ê¹€ë¯¼ìˆ˜', 'company_name': 'ì‚¼ì„±ê±´ì„¤', 'business_number': '1248100998'},
                    {'worker_id': 'C002', 'worker_name': 'ì´ì² í˜¸', 'company_name': 'ëŒ€ë¦¼ì‚°ì—…', 'business_number': '1108114055'},
                    {'worker_id': 'C003', 'worker_name': 'ë°•ì˜ì§„', 'company_name': 'GSê±´ì„¤', 'business_number': '1048145271'},
                    {'worker_id': 'C004', 'worker_name': 'ìµœì„±í›ˆ', 'company_name': 'í˜„ëŒ€ê±´ì„¤', 'business_number': '1018116293'},
                    {'worker_id': 'C005', 'worker_name': 'ì •ë¯¸ê²½', 'company_name': 'ë¡¯ë°ê±´ì„¤', 'business_number': '2148111745'},
                    {'worker_id': 'C006', 'worker_name': 'í™ê¸¸ë™', 'company_name': 'í¬ìŠ¤ì½”ê±´ì„¤', 'business_number': '5068151224'},
                    {'worker_id': 'C007', 'worker_name': 'ê¹€ìˆ˜ì—°', 'company_name': 'SKê±´ì„¤', 'business_number': '1018143363'},
                    {'worker_id': 'C008', 'worker_name': 'ì¥ë¯¼í˜¸', 'company_name': 'ë‘ì‚°ê±´ì„¤', 'business_number': '1028144723'}
                ]
                
                if search_term:
                    if search_value == 'worker_id':  # IDë¡œ ê²€ìƒ‰
                        results = [c for c in sample_contractors if search_term.upper() in c['worker_id'].upper()]
                    else:  # name (ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰)
                        results = [c for c in sample_contractors if search_term in c['worker_name']]
                else:
                    results = sample_contractors
        
        conn.close()
        return jsonify({'success': True, 'data': results})
    except Exception as e:
        logging.error(f"ê²€ìƒ‰ API ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/accidents/permanent-delete', methods=['POST'])
def permanent_delete_accidents():
    """ì„ íƒí•œ ì‚¬ê³ ë“¤ì„ ì˜êµ¬ ì‚­ì œ"""
    try:
        data = request.json
        ids = data.get('ids', [])
        
        if not ids:
            return jsonify({"success": False, "message": "ì‚­ì œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        cursor = conn.cursor()
        
        # ì„ íƒí•œ ì‚¬ê³ ë“¤ì„ ì˜êµ¬ ì‚­ì œ
        placeholders = ','.join('?' * len(ids))
        cursor.execute(f"""
            DELETE FROM accidents_cache 
            WHERE id IN ({placeholders})
        """, ids)
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "deleted_count": deleted_count,
            "message": f"{deleted_count}ê±´ì´ ì˜êµ¬ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        logging.error(f"ì‚¬ê³  ì˜êµ¬ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/accident-columns", methods=["POST"])
def add_accident_column():
    """ì‚¬ê³  í˜ì´ì§€ ë™ì  ì»¬ëŸ¼ ì¶”ê°€"""
    try:
        data = request.json
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # timeout ì¶”ê°€
        cursor = conn.cursor()
        
        # ì»¬ëŸ¼ í‚¤ ì‚¬ìš© (ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìë™ ìƒì„±)
        column_key = data.get('column_key')
        if not column_key:
            # ìƒˆ ì»¬ëŸ¼ í‚¤ ìë™ ìƒì„±
            cursor.execute("SELECT MAX(CAST(SUBSTR(column_key, 7) AS INTEGER)) FROM accident_column_config WHERE column_key LIKE 'column%'")
            max_num = cursor.fetchone()[0] or 10
            column_key = f"column{max_num + 1}"
        
        # ìµœëŒ€ ìˆœì„œ ë²ˆí˜¸ ì¡°íšŒ
        cursor.execute("SELECT MAX(column_order) FROM accident_column_config")
        max_order = cursor.fetchone()[0] or 0
        
        import json
        dropdown_options = None
        if data.get('column_type') == 'dropdown' and 'dropdown_options' in data:
            dropdown_options = json.dumps(data['dropdown_options'], ensure_ascii=False)
        
        cursor.execute("""
            INSERT INTO accident_column_config 
            (column_key, column_name, column_type, column_order, is_active, dropdown_options)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            column_key,
            data['column_name'],
            data.get('column_type', 'text'),
            max_order + 1,
            data.get('is_active', 1),
            dropdown_options
        ))
        
        # ë“œë¡­ë‹¤ìš´ íƒ€ì…ì¼ ê²½ìš° ìë™ìœ¼ë¡œ ì½”ë“œ ìƒì„±
        if data.get('column_type') == 'dropdown' and dropdown_options:
            try:
                options_list = json.loads(dropdown_options) if isinstance(dropdown_options, str) else dropdown_options
                if isinstance(options_list, list):
                    for idx, value in enumerate(options_list, 1):
                        code = f"{column_key.upper()}_{str(idx).zfill(3)}"
                        cursor.execute("""
                            INSERT OR IGNORE INTO dropdown_option_codes
                            (column_key, option_code, option_value, display_order, is_active)
                            VALUES (?, ?, ?, ?, 1)
                        """, (column_key, code, value, idx))
                    logging.info(f"ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼ {column_key}ì— ëŒ€í•œ ì½”ë“œ {len(options_list)}ê°œ ìë™ ìƒì„±")
            except Exception as e:
                logging.error(f"ë“œë¡­ë‹¤ìš´ ì½”ë“œ ìë™ ìƒì„± ì‹¤íŒ¨: {e}")
        
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True, 
            "message": "ì»¬ëŸ¼ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "column_key": column_key
        })
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/accident-columns/<int:column_id>", methods=["PUT"])
def update_accident_column(column_id):
    """ì‚¬ê³  í˜ì´ì§€ ë™ì  ì»¬ëŸ¼ ìˆ˜ì •"""
    try:
        data = request.json
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # timeout ì¶”ê°€
        cursor = conn.cursor()
        
        # í˜„ì¬ ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        cursor.execute("SELECT column_key, column_type FROM accident_column_config WHERE id = ?", (column_id,))
        column_info = cursor.fetchone()
        if not column_info:
            return jsonify({"success": False, "message": "ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        current_column_key, current_column_type = column_info
        
        # ì—…ë°ì´íŠ¸í•  í•„ë“œ ì¤€ë¹„
        update_fields = []
        params = []
        
        if 'column_name' in data:
            update_fields.append("column_name = ?")
            params.append(data['column_name'])
        
        # íƒ€ì… ë³€ê²½ ì²˜ë¦¬
        if 'column_type' in data:
            new_type = data['column_type']
            update_fields.append("column_type = ?")
            params.append(new_type)
            
            # ë“œë¡­ë‹¤ìš´ì—ì„œ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ ë³€ê²½ ì‹œ ì½”ë“œ ë¹„í™œì„±í™”
            if current_column_type == 'dropdown' and new_type != 'dropdown':
                cursor.execute("""
                    UPDATE dropdown_option_codes 
                    SET is_active = 0 
                    WHERE column_key = ?
                """, (current_column_key,))
                logging.info(f"íƒ€ì… ë³€ê²½ìœ¼ë¡œ {current_column_key}ì˜ ë“œë¡­ë‹¤ìš´ ì½”ë“œ ë¹„í™œì„±í™”")
        
        if 'is_active' in data:
            update_fields.append("is_active = ?")
            params.append(1 if data['is_active'] else 0)
        
        if 'dropdown_options' in data:
            import json
            dropdown_options = json.dumps(data['dropdown_options'], ensure_ascii=False) if data['dropdown_options'] else None
            update_fields.append("dropdown_options = ?")
            params.append(dropdown_options)
            
            # ìƒˆë¡œìš´ ë“œë¡­ë‹¤ìš´ ì˜µì…˜ì— ëŒ€í•œ ì½”ë“œ ìƒì„±
            if data.get('column_type') == 'dropdown' and dropdown_options:
                try:
                    options_list = json.loads(dropdown_options) if isinstance(dropdown_options, str) else data['dropdown_options']
                    if isinstance(options_list, list):
                        # ê¸°ì¡´ ì½”ë“œ ë¹„í™œì„±í™”
                        cursor.execute("""
                            UPDATE dropdown_option_codes 
                            SET is_active = 0 
                            WHERE column_key = ?
                        """, (current_column_key,))
                        
                        # ìƒˆ ì½”ë“œ ìƒì„±
                        for idx, value in enumerate(options_list, 1):
                            code = f"{current_column_key.upper()}_{str(idx).zfill(3)}"
                            cursor.execute("""
                                INSERT OR REPLACE INTO dropdown_option_codes
                                (column_key, option_code, option_value, display_order, is_active)
                                VALUES (?, ?, ?, ?, 1)
                            """, (current_column_key, code, value, idx))
                        logging.info(f"ë“œë¡­ë‹¤ìš´ ì˜µì…˜ ì—…ë°ì´íŠ¸: {current_column_key}ì— ì½”ë“œ {len(options_list)}ê°œ ì¬ìƒì„±")
                except Exception as e:
                    logging.error(f"ë“œë¡­ë‹¤ìš´ ì½”ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        
        if update_fields:
            update_fields.append("updated_at = CURRENT_TIMESTAMP")
            params.append(column_id)
            
            query = f"UPDATE accident_column_config SET {', '.join(update_fields)} WHERE id = ?"
            cursor.execute(query, params)
            conn.commit()
        
        conn.close()
        
        return jsonify({"success": True, "message": "ì»¬ëŸ¼ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/dropdown-codes/<column_key>", methods=["GET"])
def get_dropdown_codes(column_key):
    """íŠ¹ì • ì»¬ëŸ¼ì˜ ë“œë¡­ë‹¤ìš´ ì½”ë“œ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        # ë¨¼ì € dropdown_code_mapping í…Œì´ë¸”ì—ì„œ ì¡°íšŒ (ìƒˆë¡œìš´ ë°©ì‹)
        codes = conn.execute("""
            SELECT code as option_code, option_value, display_order 
            FROM dropdown_code_mapping
            WHERE column_key = ? AND is_active = 1
            ORDER BY display_order
        """, (column_key,)).fetchall()
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ dropdown_option_codesì—ì„œ ì¡°íšŒ (êµ¬ì‹ ë°©ì‹)
        if not codes:
            codes = conn.execute("""
                SELECT * FROM dropdown_option_codes
                WHERE column_key = ? AND is_active = 1
                ORDER BY display_order
            """, (column_key,)).fetchall()
        
        conn.close()
        
        # ì‘ë‹µ í˜•ì‹ í†µì¼
        return jsonify({
            "success": True,
            "codes": [
                {
                    "code": code['option_code'],
                    "value": code['option_value'],
                    "order": code['display_order']
                } for code in codes
            ]
        })
    except Exception as e:
        logging.error(f"ë“œë¡­ë‹¤ìš´ ì½”ë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/dropdown-codes", methods=["POST"])
def save_dropdown_codes():
    """ë“œë¡­ë‹¤ìš´ ì½”ë“œ ì €ì¥/ì—…ë°ì´íŠ¸ (ë³€ê²½ ì´ë ¥ ì¶”ì  í¬í•¨)"""
    conn = None
    try:
        data = request.json
        column_key = data.get('column_key')
        codes = data.get('codes', [])
        
        logging.info(f"[dropdown-codes] v3 handler called: column_key={column_key}, codes count={len(codes)}")
        logging.info(f"[dropdown-codes] raw codes: {codes}")
        
        # === ìœ í‹¸: JSON ë°°ì—´ ë¬¸ìì—´ì¸ì§€ íŒë³„
        def _looks_like_json_array_text(s):
            return isinstance(s, str) and s.strip().startswith('[') and s.strip().endswith(']')
        
        # === ìœ í‹¸: ì–´ë–¤ í˜•íƒœë¡œ ì™€ë„ ì¬ê·€ì ìœ¼ë¡œ í‰íƒ„í™”
        def _deep_flatten_values(value):
            import json
            out = []
            stack = [value]
            while stack:
                v = stack.pop()
                if isinstance(v, list):
                    # ë¦¬ìŠ¤íŠ¸ë©´ í•­ëª©ì„ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ìŠ¤íƒì—
                    for i in range(len(v) - 1, -1, -1):
                        stack.append(v[i])
                elif isinstance(v, str) and _looks_like_json_array_text(v):
                    # ë¬¸ìì—´ì´ë”ë¼ë„ [ ... ] ê¼´ì´ë©´ ë‹¤ì‹œ íŒŒì‹±í•´ì„œ ë°˜ë³µ
                    try:
                        parsed = json.loads(v)
                        stack.append(parsed)
                    except Exception:
                        sv = v.strip()
                        if sv:
                            out.append(sv)
                else:
                    sv = (str(v)).strip()
                    if sv:
                        out.append(sv)
            return out
        
        # ë“¤ì–´ì˜¨ codesë¥¼ ì¬ê·€ í‰íƒ„í™”í•´ì„œ ì™„ì „í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
        flattened = []
        for c in codes:  # codesëŠ” [{code: "...", value: "..."} ...] í˜•íƒœ
            vals = _deep_flatten_values(c.get('value'))
            for v in vals:
                flattened.append({'value': v})
        
        # flattenedê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ê°’ í•˜ë‚˜ë¼ë„ ë„£ê¸°
        if not flattened:
            flattened = [{'value': ''}]
        
        logging.info(f"[dropdown-codes] flattened to {len(flattened)} values: {[f['value'] for f in flattened]}")
        
        # ìš”ì²­ ì •ë³´ ìˆ˜ì§‘ (ê°ì‚¬ ë¡œê·¸ìš©)
        ip_address = request.remote_addr
        user_agent = request.headers.get('User-Agent', '')
        
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # íŠ¸ëœì­ì…˜ ì‹œì‘
        cursor.execute("BEGIN TRANSACTION")
        
        # ê¸°ì¡´ í™œì„± ì½”ë“œ ì¡°íšŒ (ë³€ê²½ ì „ ìƒíƒœ ê¸°ë¡ìš©)
        existing_codes = cursor.execute("""
            SELECT option_code, option_value, display_order 
            FROM dropdown_option_codes
            WHERE column_key = ? AND is_active = 1
        """, (column_key,)).fetchall()
        
        existing_dict = {row[0]: {'value': row[1], 'order': row[2]} for row in existing_codes}
        
        # ê¸°ì¡´ ì½”ë“œ ë¹„í™œì„±í™”
        cursor.execute("""
            UPDATE dropdown_option_codes 
            SET is_active = 0, updated_at = CURRENT_TIMESTAMP
            WHERE column_key = ?
        """, (column_key,))
        
        # dropdown_code_mapping í…Œì´ë¸” ì´ˆê¸°í™”
        cursor.execute("""
            DELETE FROM dropdown_code_mapping 
            WHERE column_key = ?
        """, (column_key,))
        
        # ìƒˆ ì½”ë“œ ì¬ìƒì„± (ìˆœë²ˆ ë¶€ì—¬)
        for idx, item in enumerate(flattened, 1):
            new_code = f"{column_key.upper()}_{str(idx).zfill(3)}"
            option_value = item['value']
            
            # dropdown_code_mapping í…Œì´ë¸”ì— ì‚½ì…
            cursor.execute("""
                INSERT INTO dropdown_code_mapping 
                (column_key, code, option_value, display_order, is_active)
                VALUES (?, ?, ?, ?, 1)
            """, (column_key, new_code, option_value, idx))
            
            # ê¸°ì¡´ ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸ (dropdown_option_codes)
            existing = cursor.execute("""
                SELECT id, option_value, display_order FROM dropdown_option_codes
                WHERE column_key = ? AND option_code = ?
            """, (column_key, new_code)).fetchone()
            
            if existing:
                old_value = existing[1]
                old_order = existing[2]
                
                # ì—…ë°ì´íŠ¸
                cursor.execute("""
                    UPDATE dropdown_option_codes 
                    SET option_value = ?, display_order = ?, is_active = 1,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE column_key = ? AND option_code = ?
                """, (option_value, idx, column_key, new_code))
                
                # ë³€ê²½ ì´ë ¥ ê¸°ë¡ (ê°’ì´ë‚˜ ìˆœì„œê°€ ë³€ê²½ëœ ê²½ìš°ë§Œ)
                if old_value != option_value or old_order != idx:
                    cursor.execute("""
                        INSERT INTO dropdown_code_audit 
                        (column_key, option_code, action_type, old_value, new_value, 
                         old_order, new_order, ip_address, user_agent)
                        VALUES (?, ?, 'UPDATE', ?, ?, ?, ?, ?, ?)
                    """, (column_key, new_code, old_value, option_value, 
                          old_order, idx, ip_address, user_agent))
            else:
                # ìƒˆë¡œ ì‚½ì…
                cursor.execute("""
                    INSERT OR REPLACE INTO dropdown_option_codes 
                    (column_key, option_code, option_value, display_order, is_active)
                    VALUES (?, ?, ?, ?, 1)
                """, (column_key, new_code, option_value, idx))
                
                # ìƒì„± ì´ë ¥ ê¸°ë¡
                cursor.execute("""
                    INSERT INTO dropdown_code_audit 
                    (column_key, option_code, action_type, new_value, new_order, 
                     ip_address, user_agent)
                    VALUES (?, ?, 'CREATE', ?, ?, ?, ?)
                """, (column_key, new_code, option_value, idx, ip_address, user_agent))
        
        # ì‚­ì œëœ ì½”ë“œ í™•ì¸ ë° ê¸°ë¡ (ì¬ìƒì„±ëœ ì½”ë“œ ê¸°ì¤€)
        new_codes = {f"{column_key.upper()}_{str(i+1).zfill(3)}" for i in range(len(flattened))}
        for old_code, old_data in existing_dict.items():
            if old_code not in new_codes:
                cursor.execute("""
                    INSERT INTO dropdown_code_audit 
                    (column_key, option_code, action_type, old_value, old_order, 
                     ip_address, user_agent)
                    VALUES (?, ?, 'DELETE', ?, ?, ?, ?)
                """, (column_key, old_code, old_data['value'], old_data['order'], 
                      ip_address, user_agent))
        
        cursor.execute("COMMIT")
        conn.close()
        
        return jsonify({"success": True, "message": "ë“œë¡­ë‹¤ìš´ ì½”ë“œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        if conn:
            conn.rollback()
            conn.close()
        logging.error(f"ë“œë¡­ë‹¤ìš´ ì½”ë“œ ì €ì¥ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/dropdown-codes/<column_key>/history", methods=["GET"])
def get_dropdown_history(column_key):
    """íŠ¹ì • ì»¬ëŸ¼ì˜ ë³€ê²½ ì´ë ¥ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        # ìµœê·¼ 100ê°œ ë³€ê²½ ì´ë ¥ ì¡°íšŒ
        history = conn.execute("""
            SELECT * FROM dropdown_code_audit
            WHERE column_key = ?
            ORDER BY changed_at DESC
            LIMIT 100
        """, (column_key,)).fetchall()
        
        # í†µê³„ ì •ë³´ ì¡°íšŒ
        stats = conn.execute("""
            SELECT * FROM dropdown_code_stats
            WHERE column_key = ?
        """, (column_key,)).fetchone()
        
        conn.close()
        
        return jsonify({
            "history": [dict(row) for row in history],
            "stats": dict(stats) if stats else None
        })
    except Exception as e:
        logging.error(f"ë³€ê²½ ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/dropdown-codes/audit-summary", methods=["GET"])
def get_audit_summary():
    """ì „ì²´ ë³€ê²½ ì´ë ¥ ìš”ì•½"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        # ìµœê·¼ 7ì¼ê°„ ë³€ê²½ í†µê³„
        recent_changes = conn.execute("""
            SELECT 
                DATE(changed_at) as date,
                COUNT(*) as total_changes,
                COUNT(DISTINCT column_key) as columns_changed
            FROM dropdown_code_audit
            WHERE changed_at >= datetime('now', '-7 days')
            GROUP BY DATE(changed_at)
            ORDER BY date DESC
        """).fetchall()
        
        # ê°€ì¥ ë§ì´ ë³€ê²½ëœ ì»¬ëŸ¼ TOP 5
        most_changed = conn.execute("""
            SELECT 
                column_key,
                COUNT(*) as change_count,
                MAX(changed_at) as last_changed
            FROM dropdown_code_audit
            GROUP BY column_key
            ORDER BY change_count DESC
            LIMIT 5
        """).fetchall()
        
        conn.close()
        
        return jsonify({
            "recent_changes": [dict(row) for row in recent_changes],
            "most_changed_columns": [dict(row) for row in most_changed]
        })
    except Exception as e:
        logging.error(f"ê°ì‚¬ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/accident-columns/<int:column_id>", methods=["DELETE"])
def delete_accident_column(column_id):
    """ì‚¬ê³  í˜ì´ì§€ ë™ì  ì»¬ëŸ¼ ì‚­ì œ (ì‹¤ì œë¡œëŠ” ë¹„í™œì„±í™”)"""
    try:
        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # timeout ì¶”ê°€
        cursor = conn.cursor()
        
        # ë¨¼ì € ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        cursor.execute("SELECT column_key, column_type FROM accident_column_config WHERE id = ?", (column_id,))
        column_info = cursor.fetchone()
        
        if column_info:
            column_key, column_type = column_info
            
            # ë“œë¡­ë‹¤ìš´ íƒ€ì…ì´ë©´ ê´€ë ¨ ì½”ë“œë„ ë¹„í™œì„±í™”
            if column_type == 'dropdown':
                cursor.execute("""
                    UPDATE dropdown_option_codes 
                    SET is_active = 0 
                    WHERE column_key = ?
                """, (column_key,))
                logging.info(f"ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼ {column_key}ì˜ ì½”ë“œë„ ë¹„í™œì„±í™”")
        
        # ì»¬ëŸ¼ì„ ì‹¤ì œë¡œ ì‚­ì œí•˜ì§€ ì•Šê³  ë¹„í™œì„±í™”
        cursor.execute("""
            UPDATE accident_column_config 
            SET is_active = 0, updated_at = CURRENT_TIMESTAMP 
            WHERE id = ?
        """, (column_id,))
        
        conn.commit()
        conn.close()
        
        return jsonify({"success": True, "message": "ì»¬ëŸ¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/accident-columns/order", methods=["PUT"])
def update_accident_columns_order():
    """ì‚¬ê³  í˜ì´ì§€ ë™ì  ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½"""
    try:
        data = request.json  # [{id: 1, column_order: 0}, {id: 2, column_order: 1}, ...]
        
        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # timeout ì¶”ê°€
        cursor = conn.cursor()
        
        for item in data:
            cursor.execute("""
                UPDATE accident_column_config 
                SET column_order = ?, updated_at = CURRENT_TIMESTAMP 
                WHERE id = ?
            """, (item['column_order'], item['id']))
        
        conn.commit()
        conn.close()
        
        return jsonify({"success": True, "message": "ìˆœì„œê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/person-master", methods=["GET"])
def get_person_master():
    """ë‹´ë‹¹ì ë§ˆìŠ¤í„° ëª©ë¡ ì¡°íšŒ (íŒì—…ìš©)"""
    try:
        search = request.args.get('search', '')
        
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        query = """
            SELECT * FROM person_master 
            WHERE is_active = 1
        """
        params = []
        
        if search:
            query += " AND (name LIKE ? OR department LIKE ? OR company_name LIKE ?)"
            search_param = f"%{search}%"
            params.extend([search_param, search_param, search_param])
        
        query += " ORDER BY name"
        
        persons = conn.execute(query, params).fetchall()
        conn.close()
        
        return jsonify({
            "success": True,
            "persons": [dict(p) for p in persons]
        })
    except Exception as e:
        logging.error(f"ë‹´ë‹¹ì ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/api/search/autocomplete", methods=["GET"])
def search_autocomplete():
    """ë²”ìš© ìë™ì™„ì„± API"""
    try:
        search_type = request.args.get('type', 'person')
        query = request.args.get('query', '').strip()
        
        if not query:
            return jsonify({"success": True, "items": []})
        
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        items = []
        
        if search_type == 'person':
            # ë¨¼ì € emp_tableì—ì„œ ê²€ìƒ‰ ì‹œë„
            try:
                results = conn.execute("""
                    SELECT DISTINCT emp_name as name, emp_dept as department, emp_company as company_name 
                    FROM emp_table 
                    WHERE enabled = 1 
                    AND (emp_name LIKE ? OR emp_id LIKE ?)
                    LIMIT 10
                """, (f'%{query}%', f'%{query}%')).fetchall()
            except:
                # emp_tableì´ ì—†ìœ¼ë©´ person_masterì—ì„œ ê²€ìƒ‰
                try:
                    results = conn.execute("""
                        SELECT DISTINCT name, department, company_name 
                        FROM person_master 
                        WHERE is_active = 1 
                        AND (name LIKE ? OR employee_id LIKE ?)
                        LIMIT 10
                    """, (f'%{query}%', f'%{query}%')).fetchall()
                except:
                    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                    dummy_data = [
                        {'name': 'í™ê¸¸ë™', 'department': 'ì•ˆì „ê´€ë¦¬íŒ€', 'company_name': 'ì‚¼ì„±ì „ì'},
                        {'name': 'ê¹€ì² ìˆ˜', 'department': 'ì‹œì„¤ê´€ë¦¬íŒ€', 'company_name': 'ì‚¼ì„±ì „ì'},
                        {'name': 'ì´ì˜í¬', 'department': 'í’ˆì§ˆê´€ë¦¬íŒ€', 'company_name': 'ì‚¼ì„±ì „ì'},
                        {'name': 'ë°•ë¯¼ìˆ˜', 'department': 'ìƒì‚°ê´€ë¦¬íŒ€', 'company_name': 'í˜‘ë ¥ì‚¬A'},
                        {'name': 'ì •ìˆ˜ì§„', 'department': 'í™˜ê²½ì•ˆì „íŒ€', 'company_name': 'í˜‘ë ¥ì‚¬B'}
                    ]
                    results = [d for d in dummy_data if query.lower() in d['name'].lower() or query in d['department']]
            
            for row in results:
                if isinstance(row, dict):
                    dept = row.get('department', '')
                    items.append({
                        'main': row.get('name', ''),
                        'sub': dept if dept else 'ë¶€ì„œ ì •ë³´ ì—†ìŒ'
                    })
                else:
                    dept = row['department'] if row['department'] else 'ë¶€ì„œ ì •ë³´ ì—†ìŒ'
                    items.append({
                        'main': row['name'],
                        'sub': dept
                    })
                
        elif search_type == 'employee_id':
            # IDë¡œ ê²€ìƒ‰
            try:
                results = conn.execute("""
                    SELECT DISTINCT emp_id as employee_id, emp_name as name, emp_dept as department 
                    FROM emp_table 
                    WHERE enabled = 1 
                    AND emp_id LIKE ?
                    LIMIT 10
                """, (f'%{query}%',)).fetchall()
            except:
                try:
                    results = conn.execute("""
                        SELECT DISTINCT employee_id, name, department 
                        FROM person_master 
                        WHERE is_active = 1 
                        AND employee_id LIKE ?
                        LIMIT 10
                    """, (f'%{query}%',)).fetchall()
                except:
                    # ë”ë¯¸ ë°ì´í„°
                    dummy_data = [
                        {'employee_id': 'E001', 'name': 'í™ê¸¸ë™', 'department': 'ì•ˆì „ê´€ë¦¬íŒ€'},
                        {'employee_id': 'E002', 'name': 'ê¹€ì² ìˆ˜', 'department': 'ì‹œì„¤ê´€ë¦¬íŒ€'},
                        {'employee_id': 'E003', 'name': 'ì´ì˜í¬', 'department': 'í’ˆì§ˆê´€ë¦¬íŒ€'},
                        {'employee_id': 'E004', 'name': 'ë°•ë¯¼ìˆ˜', 'department': 'ìƒì‚°ê´€ë¦¬íŒ€'},
                        {'employee_id': 'E005', 'name': 'ì •ìˆ˜ì§„', 'department': 'í™˜ê²½ì•ˆì „íŒ€'}
                    ]
                    results = [d for d in dummy_data if query.upper() in d['employee_id']]
            
            for row in results:
                if isinstance(row, dict):
                    items.append({
                        'main': row['employee_id'],
                        'sub': f"{row['name']} / {row['department']}"
                    })
                else:
                    items.append({
                        'main': row['employee_id'],
                        'sub': f"{row['name']} / {row['department']}"
                    })
                
        elif search_type == 'company':
            # ì—…ì²´ëª… ê²€ìƒ‰ - partners_cache í…Œì´ë¸” ì‚¬ìš©
            try:
                results = conn.execute("""
                    SELECT DISTINCT company_name, business_number 
                    FROM partners_cache 
                    WHERE company_name LIKE ?
                    LIMIT 10
                """, (f'%{query}%',)).fetchall()
            except:
                # partners_cache í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                results = []
            
            for row in results:
                items.append({
                    'main': row['company_name'],
                    'sub': row['business_number']
                })
                
        elif search_type == 'business_number':
            # ì‚¬ì—…ìë²ˆí˜¸ ê²€ìƒ‰ - partners_cache í…Œì´ë¸” ì‚¬ìš©
            try:
                results = conn.execute("""
                    SELECT DISTINCT business_number, company_name 
                    FROM partners_cache 
                    WHERE business_number LIKE ?
                    LIMIT 10
                """, (f'%{query}%',)).fetchall()
            except:
                # partners_cache í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                results = []
            
            for row in results:
                items.append({
                    'main': row['business_number'],
                    'sub': row['company_name']
                })
        
        conn.close()
        
        return jsonify({
            "success": True,
            "items": items
        })
        
    except Exception as e:
        logging.error(f"ìë™ì™„ì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@app.route("/search-popup")
def search_popup():
    """ë²”ìš© ê²€ìƒ‰ íŒì—… í˜ì´ì§€"""
    search_type = request.args.get('type', 'person')
    callback = request.args.get('callback', 'handleSearchResult')
    
    # ê²€ìƒ‰ íƒ€ì…ë³„ ì„¤ì •
    configs = {
        'person': {
            'title': 'ë‹´ë‹¹ì ê²€ìƒ‰',
            'search_title': 'ë‹´ë‹¹ì ê²€ìƒ‰',
            'placeholder': 'ì´ë¦„ ë˜ëŠ” ë¶€ì„œë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            'search_options': [
                {'value': 'person', 'label': 'ì´ë¦„'},
                {'value': 'employee_id', 'label': 'ID'}
            ],
            'columns': [
                {'field': 'employee_id', 'label': 'ID'},
                {'field': 'name', 'label': 'ì´ë¦„'},
                {'field': 'department', 'label': 'ë¶€ì„œ'}
            ]
        },
        'company': {
            'title': 'ì—…ì²´ ê²€ìƒ‰',
            'search_title': 'ì—…ì²´ ê²€ìƒ‰',
            'placeholder': 'ì—…ì²´ëª… ë˜ëŠ” ì‚¬ì—…ìë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            'search_options': [
                {'value': 'company', 'label': 'ì—…ì²´ëª…'},
                {'value': 'business_number', 'label': 'ì‚¬ì—…ìë²ˆí˜¸'}
            ],
            'columns': [
                {'field': 'company_business_number', 'label': 'ì‚¬ì—…ìë²ˆí˜¸'},
                {'field': 'company_name', 'label': 'ì—…ì²´ëª…'},
                {'field': 'representative_name', 'label': 'ëŒ€í‘œì'},
                {'field': 'business_type', 'label': 'ì—…ì¢…'},
                {'field': 'company_phone', 'label': 'ì—°ë½ì²˜'}
            ]
        },
        'building': {
            'title': 'ê±´ë¬¼ ê²€ìƒ‰',
            'search_title': 'ê±´ë¬¼ ê²€ìƒ‰',
            'placeholder': 'ê±´ë¬¼ëª… ë˜ëŠ” ê±´ë¬¼ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            'search_options': [
                {'value': 'building', 'label': 'ê±´ë¬¼ëª…'},
                {'value': 'building_code', 'label': 'ê±´ë¬¼ì½”ë“œ'}
            ],
            'columns': [
                {'field': 'building_code', 'label': 'ê±´ë¬¼ì½”ë“œ'},
                {'field': 'building_name', 'label': 'ê±´ë¬¼ëª…'}
            ]
        },
        'department': {
            'title': 'ë¶€ì„œ ê²€ìƒ‰',
            'search_title': 'ë¶€ì„œ ê²€ìƒ‰',
            'placeholder': 'ë¶€ì„œëª… ë˜ëŠ” ë¶€ì„œì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            'search_options': [
                {'value': 'department', 'label': 'ë¶€ì„œëª…'},
                {'value': 'dept_code', 'label': 'ë¶€ì„œì½”ë“œ'}
            ],
            'columns': [
                {'field': 'dept_code', 'label': 'ë¶€ì„œì½”ë“œ'},
                {'field': 'dept_name', 'label': 'ë¶€ì„œëª…'},
                {'field': 'parent_name', 'label': 'ìƒìœ„ë¶€ì„œ'},
                {'field': 'dept_level', 'label': 'ë ˆë²¨'}
            ]
        },
        'contractor': {
            'title': 'í˜‘ë ¥ì‚¬ ê·¼ë¡œì ê²€ìƒ‰',
            'search_title': 'í˜‘ë ¥ì‚¬ ê·¼ë¡œì ê²€ìƒ‰',
            'placeholder': 'ì´ë¦„ ë˜ëŠ” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            'search_options': [
                {'value': 'name', 'label': 'ì´ë¦„'},
                {'value': 'worker_id', 'label': 'ID'}
            ],
            'columns': [
                {'field': 'worker_id', 'label': 'ID'},
                {'field': 'worker_name', 'label': 'ì„±í•¨'},
                {'field': 'company_name', 'label': 'ì†Œì†ì—…ì²´'},
                {'field': 'business_number', 'label': 'ì‚¬ì—…ìë²ˆí˜¸'}
            ]
        }
    }
    
    config = configs.get(search_type, configs['person'])
    config['searchUrl'] = '/api/search'
    config['autocompleteUrl'] = '/api/search/autocomplete'
    config['callback'] = callback
    
    return render_template('search-popup.html', 
                         config=config,
                         title=config['title'],
                         search_title=config['search_title'],
                         placeholder=config['placeholder'],
                         search_options=config['search_options'],
                         is_popup=True)

# Catch-all ë¼ìš°íŠ¸ëŠ” ë§¨ ë§ˆì§€ë§‰ì— ìœ„ì¹˜ (ë‹¤ë¥¸ ëª¨ë“  ë¼ìš°íŠ¸ ë‹¤ìŒ)
@app.route("/<path:url>")
def page_view(url):
    """ì¼ë°˜ í˜ì´ì§€ ì²´í¬ (catch-all ë¼ìš°íŠ¸)"""
    conn = sqlite3.connect(DB_PATH)
    page = conn.execute("SELECT * FROM pages WHERE url = ?", (url,)).fetchone()
    conn.close()
    
    if not page:
        return "Page not found", 404
    
    return render_template("page.html", 
                         page={'url': page[1], 'title': page[2], 'content': page[3]},
                         menu=MENU_CONFIG)

@app.route("/api/accident-export")
def export_accidents_excel():
    """ì‚¬ê³  ë°ì´í„° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ"""
    try:
        import openpyxl
        from openpyxl import Workbook
        from openpyxl.styles import Font, Alignment, PatternFill
        from datetime import datetime
        import io
        
        # ê²€ìƒ‰ ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
        company_name = request.args.get('company_name', '')
        business_number = request.args.get('business_number', '')
        accident_date_start = request.args.get('accident_date_start', '')
        accident_date_end = request.args.get('accident_date_end', '')
        
        # DB ì—°ê²°
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        
        # ë™ì  ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        dynamic_columns_rows = conn.execute("""
            SELECT * FROM accident_column_config 
            WHERE is_active = 1 
            ORDER BY column_order
        """).fetchall()
        dynamic_columns = [dict(row) for row in dynamic_columns_rows]
        
        # ì‚¬ê³  ë°ì´í„° ì¡°íšŒ (partner_accident í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§)
        query = """
            SELECT * FROM accidents_cache 
            WHERE 1=1
        """
        params = []
        
        if company_name:
            query += " AND (responsible_company1 LIKE ? OR responsible_company2 LIKE ?)"
            params.extend([f'%{company_name}%', f'%{company_name}%'])
        
        if business_number:
            query += " AND (responsible_company1_no LIKE ? OR responsible_company2_no LIKE ?)"
            params.extend([f'%{business_number}%', f'%{business_number}%'])
        
        if accident_date_start:
            query += " AND accident_date >= ?"
            params.append(accident_date_start)
        
        if accident_date_end:
            query += " AND accident_date <= ?"
            params.append(accident_date_end)
        
        query += """
            ORDER BY 
                CASE 
                    WHEN accident_datetime IS NOT NULL AND accident_datetime != '' 
                    THEN accident_datetime 
                    ELSE COALESCE(accident_date, '1900-01-01') || ' 00:00' 
                END DESC, 
                accident_number DESC
        """
        
        accidents = conn.execute(query, params).fetchall()
        
        # ì—‘ì…€ ì›Œí¬ë¶ ìƒì„±
        wb = Workbook()
        ws = wb.active
        ws.title = "ì‚¬ê³  í˜„í™©"
        
        # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_align = Alignment(horizontal="center", vertical="center")
        
        # í—¤ë” ì‘ì„± (ì‚¬ê³ ë²ˆí˜¸ëŠ” ìë™ ìƒì„±ë˜ë¯€ë¡œ ì œì™¸)
        headers = [
            'ì‚¬ê³ ëª…', 'ì¬í•´ë‚ ì§œ', 'ì‹œê°„', 'ì‚¬ê³ ë“±ê¸‰', 'ì‚¬ê³ ë¶„ë¥˜',
            'ì¬í•´ìœ í˜•', 'ì¬í•´í˜•íƒœ', 'ì‚¬ì—…ì¥', 'ê±´ë¬¼', 'ì¸µ', 'ì„¸ë¶€ìœ„ì¹˜',
            'ìš”ì¼', 'ê·€ì±…í˜‘ë ¥ì‚¬(1ì°¨)', 'ê·€ì±…í˜‘ë ¥ì‚¬(1ì°¨)ì‚¬ì—…ìë²ˆí˜¸',
            'ê·€ì±…í˜‘ë ¥ì‚¬(2ì°¨)', 'ê·€ì±…í˜‘ë ¥ì‚¬(2ì°¨)ì‚¬ì—…ìë²ˆí˜¸'
        ]
        
        # ë™ì  ì»¬ëŸ¼ í—¤ë” ì¶”ê°€
        for col in dynamic_columns:
            headers.append(col['column_name'])
        
        # í—¤ë” ì“°ê¸°
        for col_idx, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_idx, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_align
        
        # ë°ì´í„° ì“°ê¸°
        for row_idx, accident_row in enumerate(accidents, 2):
            accident = dict(accident_row)
            
            # ê¸°ë³¸ í•„ë“œ ì“°ê¸° (ì‚¬ê³ ë²ˆí˜¸ ì œì™¸)
            ws.cell(row=row_idx, column=1, value=accident.get('accident_name', ''))
            ws.cell(row=row_idx, column=2, value=accident.get('accident_date', ''))
            ws.cell(row=row_idx, column=3, value=accident.get('accident_time', ''))
            ws.cell(row=row_idx, column=4, value=accident.get('accident_grade', ''))
            ws.cell(row=row_idx, column=5, value=accident.get('accident_type', ''))
            ws.cell(row=row_idx, column=6, value=accident.get('injury_type', ''))
            ws.cell(row=row_idx, column=7, value=accident.get('injury_form', ''))
            ws.cell(row=row_idx, column=8, value=accident.get('workplace', ''))
            ws.cell(row=row_idx, column=9, value=accident.get('building', ''))
            ws.cell(row=row_idx, column=10, value=accident.get('floor', ''))
            ws.cell(row=row_idx, column=11, value=accident.get('location_detail', ''))
            ws.cell(row=row_idx, column=12, value=accident.get('day_of_week', ''))
            ws.cell(row=row_idx, column=13, value=accident.get('responsible_company1', ''))
            ws.cell(row=row_idx, column=14, value=accident.get('responsible_company1_no', ''))
            ws.cell(row=row_idx, column=15, value=accident.get('responsible_company2', ''))
            ws.cell(row=row_idx, column=16, value=accident.get('responsible_company2_no', ''))
            
            # ë™ì  ì»¬ëŸ¼ ë°ì´í„° ì“°ê¸°
            import json
            custom_data = {}
            # DictAsAttr ê°ì²´ ì²˜ë¦¬ë¥¼ ìœ„í•´ hasattr ì‚¬ìš©
            if hasattr(accident, 'custom_data') and accident.custom_data:
                try:
                    custom_data = json.loads(accident.custom_data)
                except:
                    custom_data = {}
            
            for col_idx, col in enumerate(dynamic_columns, 17):
                value = custom_data.get(col['column_key'], '')
                # popup íƒ€ì… ë°ì´í„° ì²˜ë¦¬
                if isinstance(value, dict):
                    if 'name' in value:
                        value = value['name']
                    else:
                        value = str(value)
                ws.cell(row=row_idx, column=col_idx, value=value)
        
        # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width
        
        # íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
        output = io.BytesIO()
        wb.save(output)
        output.seek(0)
        
        conn.close()
        
        # íŒŒì¼ëª… ìƒì„±
        filename = f"accident_list_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        # ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    
    except Exception as e:
        logging.error(f"ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return jsonify({"success": False, "message": str(e)}), 500

# ===== ì—‘ì…€ ì„í¬íŠ¸ API =====
@app.route('/api/accident-import', methods=['POST'])
def import_accidents():
    try:
        import openpyxl
        import json
        from datetime import datetime
        import re
        
        # íŒŒì¼ í™•ì¸
        if 'file' not in request.files:
            return jsonify({"success": False, "message": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
            
        file = request.files['file']
        if file.filename == '':
            return jsonify({"success": False, "message": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
            
        if not file.filename.lower().endswith(('.xlsx', '.xls')):
            return jsonify({"success": False, "message": "ì—‘ì…€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}), 400
        
        # ì˜µì…˜ í™•ì¸
        skip_duplicates = request.form.get('skip_duplicates') == 'on'
        validate_data = request.form.get('validate_data') == 'on'
        
        # ì—‘ì…€ íŒŒì¼ ì½ê¸°
        wb = openpyxl.load_workbook(file, data_only=True)
        ws = wb.active
        
        # DB ì—°ê²°
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # accident_columns í…Œì´ë¸” í™•ì¸ ë° ìƒì„±
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='accident_columns'
        """)
        if not cursor.fetchone():
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            dynamic_columns = []
            logging.info("accident_columns í…Œì´ë¸”ì´ ì—†ì–´ì„œ ë™ì  ì»¬ëŸ¼ ì—†ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        else:
            # ë™ì  ì»¬ëŸ¼ ì¡°íšŒ
            cursor.execute("""
                SELECT column_key, column_name, column_type, dropdown_options
                FROM accident_columns 
                WHERE is_active = 1 
                ORDER BY column_order
            """)
            dynamic_columns = cursor.fetchall()
        
        # í—¤ë” ë§¤í•‘ (í•œê¸€ í—¤ë”ëª… -> DB ì»¬ëŸ¼ëª…)
        # ì£¼ì˜: ì‚¬ê³ ë²ˆí˜¸ëŠ” ìë™ ìƒì„±í•˜ë¯€ë¡œ ë§¤í•‘ì—ì„œ ì œì™¸
        header_mapping = {
            'ì‚¬ê³ ëª…': 'accident_name', 
            'ì¬í•´ë‚ ì§œ': 'accident_date',
            'ì‹œê°„': 'accident_time',
            'ì‚¬ê³ ë“±ê¸‰': 'accident_level',
            'ì‚¬ê³ ë¶„ë¥˜': 'accident_classification',
            'ì¬í•´ìœ í˜•': 'disaster_type',
            'ì¬í•´í˜•íƒœ': 'disaster_form',
            'ì‚¬ì—…ì¥': 'workplace',
            'ê±´ë¬¼': 'building',
            'ì¸µ': 'floor',
            'ì„¸ë¶€ìœ„ì¹˜': 'location_detail',
            'ìš”ì¼': 'day_of_week',
            'ê·€ì±…í˜‘ë ¥ì‚¬(1ì°¨)': 'responsible_company1',
            'ê·€ì±…í˜‘ë ¥ì‚¬(1ì°¨)ì‚¬ì—…ìë²ˆí˜¸': 'responsible_company1_no',
            'ê·€ì±…í˜‘ë ¥ì‚¬(2ì°¨)': 'responsible_company2',
            'ê·€ì±…í˜‘ë ¥ì‚¬(2ì°¨)ì‚¬ì—…ìë²ˆí˜¸': 'responsible_company2_no',
            'ì²˜ë¦¬ìƒíƒœ': 'processing_status',
            'ì¡°ì¹˜ì‚¬í•­': 'measures',
            'ì¬ë°œë°©ì§€ëŒ€ì±…': 'prevention_measures',
            'ë‹´ë‹¹ë¶€ì„œ': 'department',
            'ë‹´ë‹¹ì': 'manager',
            'ì™„ë£Œì˜ˆì •ì¼': 'completion_date',
            'ì›ì¸ë¶„ì„': 'cause_analysis',
            'ì²¨ë¶€ë¬¸ì„œ': 'attachment',
            'ë°œìƒìœ„ì¹˜': 'occurrence_location'
        }
        
        # ë™ì  ì»¬ëŸ¼ ë§¤í•‘ ì¶”ê°€
        for col in dynamic_columns:
            header_mapping[col['column_name']] = col['column_key']
        
        # ì²« ë²ˆì§¸ í–‰ì—ì„œ í—¤ë” ì½ê¸°
        headers = []
        for cell in ws[1]:
            headers.append(cell.value if cell.value else '')
        
        success_count = 0
        error_count = 0
        errors = []
        
        # í—¤ë” ì •ë³´ ë¡œê·¸
        logging.info(f"ì—‘ì…€ í—¤ë”: {headers}")
        logging.info(f"í—¤ë” ë§¤í•‘: {header_mapping}")
        
        # ë°ì´í„° í–‰ ì²˜ë¦¬ (2í–‰ë¶€í„°)
        for row_idx, row in enumerate(ws.iter_rows(min_row=2, values_only=True), 2):
            try:
                # ë¹ˆ í–‰ ê±´ë„ˆë›°ê¸°
                if not any(row):
                    continue
                
                logging.info(f"ì²˜ë¦¬ ì¤‘ì¸ í–‰ {row_idx}: {row}")
                
                # ë°ì´í„° ë§¤í•‘
                data = {}
                custom_data = {}
                
                for col_idx, cell_value in enumerate(row):
                    if col_idx >= len(headers):
                        break
                        
                    header = headers[col_idx]
                    if not header or not cell_value:
                        continue
                        
                    # ë¬¸ìì—´ë¡œ ë³€í™˜
                    str_value = str(cell_value).strip()
                    if not str_value:
                        continue
                    
                    # í—¤ë” ë§¤í•‘
                    if header in header_mapping:
                        db_column = header_mapping[header]
                        
                        # ê¸°ë³¸ ì»¬ëŸ¼ì¸ì§€ ë™ì  ì»¬ëŸ¼ì¸ì§€ í™•ì¸ (accident_numberëŠ” ìë™ ìƒì„±í•˜ë¯€ë¡œ ì œì™¸)
                        if db_column in ['accident_name', 'accident_date', 'accident_time', 
                                       'accident_level', 'accident_classification', 'disaster_type', 'disaster_form',
                                       'workplace', 'building', 'floor', 'location_detail', 'day_of_week',
                                       'responsible_company1', 'responsible_company1_no', 'responsible_company2',
                                       'responsible_company2_no', 'processing_status', 'measures', 
                                       'prevention_measures', 'department', 'manager', 'completion_date',
                                       'cause_analysis', 'attachment', 'occurrence_location']:
                            data[db_column] = str_value
                        else:
                            # ë™ì  ì»¬ëŸ¼
                            custom_data[db_column] = str_value
                
                # ì‚¬ê³ ë²ˆí˜¸ëŠ” í•­ìƒ ìë™ ìƒì„± (ì‚¬ìš©ì ì…ë ¥ ë¬´ì‹œ)
                if data.get('accident_date'):
                    # ì¬í•´ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ACCYYMMDD í˜•ì‹ìœ¼ë¡œ ìƒì„±
                    try:
                        accident_date = data['accident_date']
                        if isinstance(accident_date, str):
                            # ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±
                            for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Y.%m.%d']:
                                try:
                                    dt = datetime.strptime(accident_date, fmt)
                                    break
                                except ValueError:
                                    continue
                            else:
                                # íŒŒì‹± ì‹¤íŒ¨ì‹œ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
                                dt = datetime.now()
                        else:
                            dt = datetime.now()
                        
                        # ACCYYMMDD ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±
                        base_number = dt.strftime('ACC%y%m%d')
                        
                        # ê°™ì€ ë‚ ì§œì— ì´ë¯¸ ìˆëŠ” ì‚¬ê³  ìˆ˜ í™•ì¸
                        cursor.execute("""
                            SELECT COUNT(*) FROM accidents 
                            WHERE accident_number LIKE ?
                        """, (base_number + '%',))
                        count = cursor.fetchone()[0]
                        
                        # ì¼ë ¨ë²ˆí˜¸ ì¶”ê°€ (01, 02, 03...)
                        sequence = str(count + 1).zfill(2)
                        data['accident_number'] = base_number + sequence
                        
                    except Exception as e:
                        # ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ ìë™ ìƒì„± ë°©ì‹ ì‚¬ìš©
                        data['accident_number'] = generate_manual_accident_number(cursor)
                else:
                    # ì¬í•´ë‚ ì§œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìë™ ìƒì„± ë°©ì‹ ì‚¬ìš©
                    data['accident_number'] = generate_manual_accident_number(cursor)
                
                # ì¤‘ë³µ í™•ì¸
                if skip_duplicates and data.get('accident_number'):
                    cursor.execute("SELECT COUNT(*) FROM accidents WHERE accident_number = ?", (data['accident_number'],))
                    if cursor.fetchone()[0] > 0:
                        continue
                
                # ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬ - ê°„ë‹¨í™”
                if data.get('accident_date'):
                    date_str = str(data['accident_date']).strip()
                    if date_str and date_str != 'None':
                        data['accident_date'] = date_str
                    else:
                        # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •
                        data['accident_date'] = datetime.now().strftime('%Y-%m-%d')
                
                logging.info(f"ë§¤í•‘ëœ ë°ì´í„°: {data}")
                logging.info(f"ë™ì  ì»¬ëŸ¼ ë°ì´í„°: {custom_data}")
                
                # ìµœì†Œ í•„ìˆ˜ ë°ì´í„° í™•ì¸
                if not data.get('accident_number'):
                    logging.error(f"í–‰ {row_idx}: ì‚¬ê³ ë²ˆí˜¸ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                    continue
                
                # DB ì €ì¥ - ê°„ë‹¨í™”
                try:
                    # ê¸°ë³¸ í•„ë“œë§Œ ë¨¼ì € ì €ì¥
                    insert_sql = """
                        INSERT INTO accidents 
                        (accident_number, accident_name, accident_date, created_at) 
                        VALUES (?, ?, ?, ?)
                    """
                    values = [
                        data['accident_number'],
                        data.get('accident_name', ''),
                        data.get('accident_date', datetime.now().strftime('%Y-%m-%d')),
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    ]
                    
                    logging.info(f"ì‹¤í–‰í•  SQL: {insert_sql}")
                    logging.info(f"SQL íŒŒë¼ë¯¸í„°: {values}")
                    
                    cursor.execute(insert_sql, values)
                    
                except Exception as sql_error:
                    logging.error(f"SQL ì‹¤í–‰ ì˜¤ë¥˜: {sql_error}")
                    raise sql_error
                
                success_count += 1
                
            except Exception as e:
                error_count += 1
                errors.append(f"í–‰ {row_idx}: {str(e)}")
                continue
        
        conn.commit()
        conn.close()
        
        result = {
            "success": True,
            "success_count": success_count,
            "error_count": error_count
        }
        
        if errors:
            result["errors"] = errors[:10]  # ìµœëŒ€ 10ê°œ ì˜¤ë¥˜ë§Œ ë°˜í™˜
            
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"ì—‘ì…€ ì„í¬íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return jsonify({"success": False, "message": str(e)}), 500

# ===== í˜‘ë ¥ì‚¬ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ API =====
@app.route('/api/partners/export')
def export_partners_to_excel():
    try:
        import openpyxl
        from openpyxl import Workbook
        from openpyxl.styles import Font, Alignment, PatternFill
        from datetime import datetime
        import io
        
        # ê²€ìƒ‰ ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
        company_name = request.args.get('company_name', '')
        business_number = request.args.get('business_number', '')
        business_type_major = request.args.get('business_type_major', '')
        business_type_minor = request.args.get('business_type_minor', '')
        workers_min = request.args.get('workers_min', '')
        workers_max = request.args.get('workers_max', '')
        
        # í˜‘ë ¥ì‚¬ ë°ì´í„° ì¡°íšŒ (partner_standards í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§)
        try:
            conn = sqlite3.connect(DB_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # ì¿¼ë¦¬ êµ¬ì„± (ì‚­ì œë˜ì§€ ì•Šì€ ë°ì´í„°ë§Œ)
            query = "SELECT * FROM partners_cache WHERE (is_deleted = 0 OR is_deleted IS NULL)"
            params = []
            
            if company_name:
                query += " AND company_name LIKE ?"
                params.append(f'%{company_name}%')
            
            if business_number:
                query += " AND business_number LIKE ?"
                params.append(f'%{business_number}%')
                
            if business_type_major:
                query += " AND business_type_major = ?"
                params.append(business_type_major)
                
            if business_type_minor:
                query += " AND business_type_minor = ?"
                params.append(business_type_minor)
                
            if workers_min:
                try:
                    min_val = int(workers_min)
                    query += " AND permanent_workers >= ?"
                    params.append(min_val)
                except ValueError:
                    pass
                    
            if workers_max:
                try:
                    max_val = int(workers_max)
                    query += " AND permanent_workers <= ?"
                    params.append(max_val)
                except ValueError:
                    pass
            
            query += " ORDER BY company_name"
            
            partners = cursor.execute(query, params).fetchall()
            
            # ì—‘ì…€ ì›Œí¬ë¶ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "í˜‘ë ¥ì‚¬ ê¸°ì¤€ì •ë³´"
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            header_align = Alignment(horizontal="center", vertical="center")
            
            # í—¤ë” ì‘ì„±
            headers = [
                'í˜‘ë ¥ì‚¬ëª…', 'ì‚¬ì—…ìë²ˆí˜¸', 'Class', 'ì—…ì¢…(ëŒ€ë¶„ë¥˜)', 'ì—…ì¢…(ì†Œë¶„ë¥˜)',
                'ìœ„í—˜ì‘ì—…ì—¬ë¶€', 'ëŒ€í‘œìì„±ëª…', 'ì£¼ì†Œ', 'í‰ê· ì—°ë ¹', 'ë§¤ì¶œì•¡', 
                'ê±°ë˜ì°¨ìˆ˜', 'ìƒì‹œê·¼ë¡œì'
            ]
            
            # í—¤ë” ì“°ê¸°
            for col_idx, header in enumerate(headers, 1):
                cell = ws.cell(row=1, column=col_idx, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_align
            
            # ë°ì´í„° ì“°ê¸°
            for row_idx, partner_row in enumerate(partners, 2):
                partner = dict(partner_row)
                
                ws.cell(row=row_idx, column=1, value=partner.get('company_name', ''))
                ws.cell(row=row_idx, column=2, value=partner.get('business_number', ''))
                ws.cell(row=row_idx, column=3, value=partner.get('partner_class', ''))
                ws.cell(row=row_idx, column=4, value=partner.get('business_type_major', ''))
                ws.cell(row=row_idx, column=5, value=partner.get('business_type_minor', ''))
                
                # ìœ„í—˜ì‘ì—…ì—¬ë¶€ ì²˜ë¦¬
                hazard_work = partner.get('hazard_work_flag', '')
                hazard_text = 'ì˜ˆ' if hazard_work == 'O' else 'ì•„ë‹ˆì˜¤' if hazard_work == 'X' else ''
                ws.cell(row=row_idx, column=6, value=hazard_text)
                
                ws.cell(row=row_idx, column=7, value=partner.get('representative', ''))
                ws.cell(row=row_idx, column=8, value=partner.get('address', ''))
                ws.cell(row=row_idx, column=9, value=partner.get('average_age', ''))
                
                # ë§¤ì¶œì•¡ ì²˜ë¦¬ (ì–µì› ë‹¨ìœ„)
                revenue = partner.get('annual_revenue')
                if revenue:
                    revenue_text = f"{revenue // 100000000}ì–µì›"
                else:
                    revenue_text = ''
                ws.cell(row=row_idx, column=10, value=revenue_text)
                
                ws.cell(row=row_idx, column=11, value=partner.get('transaction_count', ''))
                
                # ìƒì‹œê·¼ë¡œì ì²˜ë¦¬
                workers = partner.get('permanent_workers')
                workers_text = f"{workers}ëª…" if workers else ''
                ws.cell(row=row_idx, column=12, value=workers_text)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
            output = io.BytesIO()
            wb.save(output)
            output.seek(0)
            
            conn.close()
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"partners_list_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            
            # ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
            return send_file(
                output,
                mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                as_attachment=True,
                download_name=filename
            )
            
        except Exception as db_error:
            logging.error(f"í˜‘ë ¥ì‚¬ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {db_error}")
            # ë”ë¯¸ ë°ì´í„°ë¡œ ëŒ€ì²´
            wb = Workbook()
            ws = wb.active
            ws.title = "í˜‘ë ¥ì‚¬ ê¸°ì¤€ì •ë³´"
            
            # í—¤ë”ë§Œ ìˆëŠ” ë¹ˆ íŒŒì¼ ìƒì„±
            headers = [
                'í˜‘ë ¥ì‚¬ëª…', 'ì‚¬ì—…ìë²ˆí˜¸', 'Class', 'ì—…ì¢…(ëŒ€ë¶„ë¥˜)', 'ì—…ì¢…(ì†Œë¶„ë¥˜)',
                'ìœ„í—˜ì‘ì—…ì—¬ë¶€', 'ëŒ€í‘œìì„±ëª…', 'ì£¼ì†Œ', 'í‰ê· ì—°ë ¹', 'ë§¤ì¶œì•¡', 
                'ê±°ë˜ì°¨ìˆ˜', 'ìƒì‹œê·¼ë¡œì'
            ]
            
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            header_align = Alignment(horizontal="center", vertical="center")
            
            for col_idx, header in enumerate(headers, 1):
                cell = ws.cell(row=1, column=col_idx, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_align
            
            # ìƒ˜í”Œ ë°ì´í„° 1í–‰ ì¶”ê°€
            sample_data = [
                'ìƒ˜í”Œ í˜‘ë ¥ì‚¬', '123-45-67890', 'A', 'ì œì¡°ì—…', 'ì „ìì œí’ˆ',
                'ì˜ˆ', 'ê¹€ëŒ€í‘œ', 'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬', '35', '100ì–µì›', '5', '50ëª…'
            ]
            for col_idx, value in enumerate(sample_data, 1):
                ws.cell(row=2, column=col_idx, value=value)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 30)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            output = io.BytesIO()
            wb.save(output)
            output.seek(0)
            
            filename = f"partners_list_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            
            return send_file(
                output,
                mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                as_attachment=True,
                download_name=filename
            )
    
    except Exception as e:
        logging.error(f"í˜‘ë ¥ì‚¬ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return jsonify({"success": False, "message": str(e)}), 500

# ===== í˜‘ë ¥ì‚¬ ì‚­ì œ API =====
@app.route('/api/partners/delete', methods=['POST'])
def delete_partners():
    try:
        data = request.get_json()
        business_numbers = data.get('business_numbers', [])
        
        if not business_numbers:
            return jsonify({"success": False, "message": "ì‚­ì œí•  í˜‘ë ¥ì‚¬ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
        
        # DB ì—°ê²°
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Soft delete (is_deleted = 1ë¡œ ì„¤ì •)
        placeholders = ','.join('?' * len(business_numbers))
        cursor.execute(f"""
            UPDATE partners_cache 
            SET is_deleted = 1 
            WHERE business_number IN ({placeholders})
        """, business_numbers)
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "deleted_count": deleted_count,
            "message": f"{deleted_count}ê°œì˜ í˜‘ë ¥ì‚¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "reload": True  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í•„ìš” í”Œë˜ê·¸ ì¶”ê°€
        })
        
    except Exception as e:
        logging.error(f"í˜‘ë ¥ì‚¬ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

# ìƒˆë¡œìš´ ë©”ë‰´ë“¤ì˜ ë¼ìš°íŠ¸
@app.route('/work-safety')
def work_safety():
    """ì‘ì—…ì•ˆì „ í˜„í™© í˜ì´ì§€"""
    return render_template('work-safety.html', menu=menu)

@app.route('/risk-assessment')
def risk_assessment():
    """ìœ„í—˜ì„±í‰ê°€ í˜„í™© í˜ì´ì§€"""
    return render_template('risk-assessment.html', menu=menu)

@app.route('/qualification-assessment')
def qualification_assessment():
    """ì ê²©ì„±í‰ê°€ í˜„í™© í˜ì´ì§€"""
    return render_template('qualification-assessment.html', menu=menu)

@app.route('/safety-culture')
def safety_culture():
    """ì•ˆì „ë¬¸í™” í˜„í™© í˜ì´ì§€"""
    return render_template('safety-culture.html', menu=menu)

@app.after_request
def add_header(response):
    """ì‘ë‹µ í—¤ë” ì¶”ê°€ - ìºì‹œ ë¬´íš¨í™”"""
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response


@app.route('/api/partner-change-request', methods=['POST'])
def create_partner_change_request():
    """ê¸°ì¤€ì •ë³´ ë³€ê²½ìš”ì²­ ë“±ë¡ API"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['requester_name', 'requester_department', 'company_name', 
                          'business_number', 'change_type', 'current_value', 'new_value', 'change_reason']
        
        for field in required_fields:
            if not data.get(field):
                return jsonify({"success": False, "message": f"{field} í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # DB ì—°ê²° ë° í…Œì´ë¸” ìƒì„±
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # ë³€ê²½ìš”ì²­ í…Œì´ë¸” ìƒì„± (ì—†ì„ ê²½ìš°)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS partner_change_requests (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                requester_name TEXT NOT NULL,
                requester_department TEXT NOT NULL,
                company_name TEXT NOT NULL,
                business_number TEXT NOT NULL,
                change_type TEXT NOT NULL,
                current_value TEXT NOT NULL,
                new_value TEXT NOT NULL,
                change_reason TEXT NOT NULL,
                status TEXT DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ë³€ê²½ìš”ì²­ ë°ì´í„° ì‚½ì…
        cursor.execute("""
            INSERT INTO partner_change_requests 
            (requester_name, requester_department, company_name, business_number, 
             change_type, current_value, new_value, change_reason)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            data['requester_name'],
            data['requester_department'],
            data['company_name'],
            data['business_number'],
            data['change_type'],
            data['current_value'],
            data['new_value'],
            data['change_reason']
        ))
        
        request_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "request_id": request_id,
            "message": "ë³€ê²½ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "reload": True
        })
        
    except Exception as e:
        logging.error(f"ë³€ê²½ìš”ì²­ ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


if __name__ == "__main__":
    print("Flask ì•± ì‹œì‘ ì¤‘...", flush=True)
    print(f"partner-accident ë¼ìš°íŠ¸ ë“±ë¡ë¨: {'/partner-accident' in [rule.rule for rule in app.url_map.iter_rules()]}", flush=True)
    app.run(host="0.0.0.0", port=5000, debug=True)